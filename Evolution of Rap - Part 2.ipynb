{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evolution of Rap - Part 2\n",
    "### *Using Machine Learning to Predict Top Rap Tracks*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "\n",
    "I will be using the same data pulled from Part 1 for this analysis. See Part 1 for details on how this dataset was created. After combining data from Billboard, Spotify, and Genius, I chose to focus on two questions:\n",
    "1. How has rap changed over the years? Can I represent this visually?\n",
    "2. Is it possible to accurately predict which tracks will break into the top 5 spots on Billboard? Do top 5 rap songs across all years share any similarities? \n",
    "\n",
    "This notebook will focus on the second question above.\n",
    "\n",
    "**The analysis resulted in the following conclusions:**\n",
    "1. Random forest was the best model but still had trouble predicting a track correctly as \"Top 5\". This suggests that top 5 tracks are very diverse on an audio feature basis.\n",
    "2. Features derived from the actual lyrics will likely be needed to improve model performance (common words, bigrams, and trigrams)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "complete_df_3 = pd.read_pickle(\"complete_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df_3[\"week\"] = pd.to_datetime(complete_df_3[\"week\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = complete_df_3.groupby(by=[\"artist\",\"title\"], as_index=False).apply(lambda x : x[x[\"current_rank\"]==(x[\"current_rank\"].min())])\n",
    "data_df = data_df.sort_values(by=[\"week\",\"current_rank\"],ascending=[False,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>current_rank</th>\n",
       "      <th>peak_pos</th>\n",
       "      <th>title</th>\n",
       "      <th>week</th>\n",
       "      <th>weeks_on_chart</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>spotify_popularity</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>valence</th>\n",
       "      <th>processed_lyrics</th>\n",
       "      <th>era</th>\n",
       "      <th>mean_sentiment</th>\n",
       "      <th>std_sentiment</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>word_count</th>\n",
       "      <th>words_per_second</th>\n",
       "      <th>unique_word_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <th>0</th>\n",
       "      <td>Cardi B Featuring Megan Thee Stallion</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>WAP</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>3</td>\n",
       "      <td>187541.0</td>\n",
       "      <td>True</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01940</td>\n",
       "      <td>0.357</td>\n",
       "      <td>[puta, en, esta, casa, hay, alguna, puta, en, ...</td>\n",
       "      <td>Trap/Mumble Era (2015-Present)</td>\n",
       "      <td>-0.020066</td>\n",
       "      <td>0.103138</td>\n",
       "      <td>187.541</td>\n",
       "      <td>698</td>\n",
       "      <td>3.721853</td>\n",
       "      <td>0.402579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <th>1</th>\n",
       "      <td>Drake Featuring Lil Durk</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Laugh Now Cry Later</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>2</td>\n",
       "      <td>261492.0</td>\n",
       "      <td>True</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24400</td>\n",
       "      <td>0.522</td>\n",
       "      <td>[woah, woah, yeah, sometim, we, laugh, and, so...</td>\n",
       "      <td>Trap/Mumble Era (2015-Present)</td>\n",
       "      <td>-0.055024</td>\n",
       "      <td>0.333150</td>\n",
       "      <td>261.492</td>\n",
       "      <td>602</td>\n",
       "      <td>2.302174</td>\n",
       "      <td>0.338870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>4</th>\n",
       "      <td>24kGoldn Featuring iann dior</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Mood</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>2</td>\n",
       "      <td>140525.0</td>\n",
       "      <td>True</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.756</td>\n",
       "      <td>[ohohoh, yeah, yeah, yeah, yeah, yeah, whi, yo...</td>\n",
       "      <td>Trap/Mumble Era (2015-Present)</td>\n",
       "      <td>0.198549</td>\n",
       "      <td>0.348027</td>\n",
       "      <td>140.525</td>\n",
       "      <td>426</td>\n",
       "      <td>3.031489</td>\n",
       "      <td>0.295775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2462</th>\n",
       "      <th>12</th>\n",
       "      <td>Saweetie</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>Tap In</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>5</td>\n",
       "      <td>139413.0</td>\n",
       "      <td>True</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00576</td>\n",
       "      <td>0.432</td>\n",
       "      <td>[dont, ever, stop, if, you, want, to, be, on, ...</td>\n",
       "      <td>Trap/Mumble Era (2015-Present)</td>\n",
       "      <td>-0.116385</td>\n",
       "      <td>0.368274</td>\n",
       "      <td>139.413</td>\n",
       "      <td>415</td>\n",
       "      <td>2.976767</td>\n",
       "      <td>0.445783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <th>22</th>\n",
       "      <td>Money Man Featuring Lil Baby</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>2020-09-05</td>\n",
       "      <td>2</td>\n",
       "      <td>182857.0</td>\n",
       "      <td>True</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14600</td>\n",
       "      <td>0.459</td>\n",
       "      <td>[yo, nflate, spice, that, bitch, up, burnin, o...</td>\n",
       "      <td>Trap/Mumble Era (2015-Present)</td>\n",
       "      <td>-0.027759</td>\n",
       "      <td>0.337909</td>\n",
       "      <td>182.857</td>\n",
       "      <td>741</td>\n",
       "      <td>4.052347</td>\n",
       "      <td>0.453441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <th>38302</th>\n",
       "      <td>Boogie Down Productions</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Jack Of Spades</td>\n",
       "      <td>1989-03-11</td>\n",
       "      <td>1</td>\n",
       "      <td>289373.0</td>\n",
       "      <td>False</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.568</td>\n",
       "      <td>[again, we, start, let, me, say, my, part, abo...</td>\n",
       "      <td>Golden Era (1989-1997)</td>\n",
       "      <td>-0.032921</td>\n",
       "      <td>0.317302</td>\n",
       "      <td>289.373</td>\n",
       "      <td>554</td>\n",
       "      <td>1.914484</td>\n",
       "      <td>0.460289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <th>38308</th>\n",
       "      <td>Cash Money &amp; Marvelous</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>Find An Ugly Woman</td>\n",
       "      <td>1989-03-11</td>\n",
       "      <td>1</td>\n",
       "      <td>204226.0</td>\n",
       "      <td>True</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.880</td>\n",
       "      <td>[tictoc, toctic, tictoc, you, dont, stop, you,...</td>\n",
       "      <td>Golden Era (1989-1997)</td>\n",
       "      <td>0.027437</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>204.226</td>\n",
       "      <td>481</td>\n",
       "      <td>2.355234</td>\n",
       "      <td>0.388773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <th>38310</th>\n",
       "      <td>Eric B. &amp; Rakim</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>The R</td>\n",
       "      <td>1989-03-11</td>\n",
       "      <td>1</td>\n",
       "      <td>262800.0</td>\n",
       "      <td>False</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00556</td>\n",
       "      <td>0.809</td>\n",
       "      <td>[whoever, underestim, still, wait, pumpin, the...</td>\n",
       "      <td>Golden Era (1989-1997)</td>\n",
       "      <td>0.038239</td>\n",
       "      <td>0.194063</td>\n",
       "      <td>262.800</td>\n",
       "      <td>458</td>\n",
       "      <td>1.742770</td>\n",
       "      <td>0.379913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <th>38314</th>\n",
       "      <td>Kid 'N Play</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>Gittin' Funky</td>\n",
       "      <td>1989-03-11</td>\n",
       "      <td>1</td>\n",
       "      <td>284040.0</td>\n",
       "      <td>False</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01930</td>\n",
       "      <td>0.432</td>\n",
       "      <td>[come, on, come, on, babi, yeah, kid, the, ing...</td>\n",
       "      <td>Golden Era (1989-1997)</td>\n",
       "      <td>0.052888</td>\n",
       "      <td>0.281358</td>\n",
       "      <td>284.040</td>\n",
       "      <td>542</td>\n",
       "      <td>1.908182</td>\n",
       "      <td>0.464945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <th>38315</th>\n",
       "      <td>Sweet Tee</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>On The Smooth Tip</td>\n",
       "      <td>1989-03-11</td>\n",
       "      <td>1</td>\n",
       "      <td>246293.0</td>\n",
       "      <td>False</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1989</td>\n",
       "      <td>...</td>\n",
       "      <td>0.12600</td>\n",
       "      <td>0.937</td>\n",
       "      <td>[testin, my, mic, onetwo, onetwo, im, here, to...</td>\n",
       "      <td>Golden Era (1989-1997)</td>\n",
       "      <td>0.109902</td>\n",
       "      <td>0.233325</td>\n",
       "      <td>246.293</td>\n",
       "      <td>500</td>\n",
       "      <td>2.030102</td>\n",
       "      <td>0.504000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5599 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           artist  current_rank  peak_pos  \\\n",
       "402  0      Cardi B Featuring Megan Thee Stallion             1         1   \n",
       "791  1                   Drake Featuring Lil Durk             2         2   \n",
       "22   4               24kGoldn Featuring iann dior             5         5   \n",
       "2462 12                                  Saweetie            13        13   \n",
       "1989 22              Money Man Featuring Lil Baby            23        23   \n",
       "...                                           ...           ...       ...   \n",
       "306  38302                Boogie Down Productions             3         3   \n",
       "406  38308                 Cash Money & Marvelous            11        11   \n",
       "902  38310                        Eric B. & Rakim            14        14   \n",
       "1502 38314                            Kid 'N Play            24        24   \n",
       "2616 38315                              Sweet Tee            26        26   \n",
       "\n",
       "                          title       week  weeks_on_chart  duration_ms  \\\n",
       "402  0                      WAP 2020-09-05               3     187541.0   \n",
       "791  1      Laugh Now Cry Later 2020-09-05               2     261492.0   \n",
       "22   4                     Mood 2020-09-05               2     140525.0   \n",
       "2462 12                  Tap In 2020-09-05               5     139413.0   \n",
       "1989 22                      24 2020-09-05               2     182857.0   \n",
       "...                         ...        ...             ...          ...   \n",
       "306  38302       Jack Of Spades 1989-03-11               1     289373.0   \n",
       "406  38308   Find An Ugly Woman 1989-03-11               1     204226.0   \n",
       "902  38310                The R 1989-03-11               1     262800.0   \n",
       "1502 38314        Gittin' Funky 1989-03-11               1     284040.0   \n",
       "2616 38315    On The Smooth Tip 1989-03-11               1     246293.0   \n",
       "\n",
       "           explicit  spotify_popularity  year  ...  acousticness  valence  \\\n",
       "402  0         True               100.0  2020  ...       0.01940    0.357   \n",
       "791  1         True                96.0  2020  ...       0.24400    0.522   \n",
       "22   4         True                96.0  2020  ...       0.22100    0.756   \n",
       "2462 12        True                87.0  2020  ...       0.00576    0.432   \n",
       "1989 22        True                80.0  2020  ...       0.14600    0.459   \n",
       "...             ...                 ...   ...  ...           ...      ...   \n",
       "306  38302    False                28.0  1989  ...       0.01270    0.568   \n",
       "406  38308     True                12.0  1989  ...       0.00261    0.880   \n",
       "902  38310    False                60.0  1989  ...       0.00556    0.809   \n",
       "1502 38314    False                34.0  1989  ...       0.01930    0.432   \n",
       "2616 38315    False                13.0  1989  ...       0.12600    0.937   \n",
       "\n",
       "                                             processed_lyrics  \\\n",
       "402  0      [puta, en, esta, casa, hay, alguna, puta, en, ...   \n",
       "791  1      [woah, woah, yeah, sometim, we, laugh, and, so...   \n",
       "22   4      [ohohoh, yeah, yeah, yeah, yeah, yeah, whi, yo...   \n",
       "2462 12     [dont, ever, stop, if, you, want, to, be, on, ...   \n",
       "1989 22     [yo, nflate, spice, that, bitch, up, burnin, o...   \n",
       "...                                                       ...   \n",
       "306  38302  [again, we, start, let, me, say, my, part, abo...   \n",
       "406  38308  [tictoc, toctic, tictoc, you, dont, stop, you,...   \n",
       "902  38310  [whoever, underestim, still, wait, pumpin, the...   \n",
       "1502 38314  [come, on, come, on, babi, yeah, kid, the, ing...   \n",
       "2616 38315  [testin, my, mic, onetwo, onetwo, im, here, to...   \n",
       "\n",
       "                                       era  mean_sentiment  std_sentiment  \\\n",
       "402  0      Trap/Mumble Era (2015-Present)       -0.020066       0.103138   \n",
       "791  1      Trap/Mumble Era (2015-Present)       -0.055024       0.333150   \n",
       "22   4      Trap/Mumble Era (2015-Present)        0.198549       0.348027   \n",
       "2462 12     Trap/Mumble Era (2015-Present)       -0.116385       0.368274   \n",
       "1989 22     Trap/Mumble Era (2015-Present)       -0.027759       0.337909   \n",
       "...                                    ...             ...            ...   \n",
       "306  38302          Golden Era (1989-1997)       -0.032921       0.317302   \n",
       "406  38308          Golden Era (1989-1997)        0.027437       0.371938   \n",
       "902  38310          Golden Era (1989-1997)        0.038239       0.194063   \n",
       "1502 38314          Golden Era (1989-1997)        0.052888       0.281358   \n",
       "2616 38315          Golden Era (1989-1997)        0.109902       0.233325   \n",
       "\n",
       "           duration_sec word_count  words_per_second  unique_word_proportion  \n",
       "402  0          187.541        698          3.721853                0.402579  \n",
       "791  1          261.492        602          2.302174                0.338870  \n",
       "22   4          140.525        426          3.031489                0.295775  \n",
       "2462 12         139.413        415          2.976767                0.445783  \n",
       "1989 22         182.857        741          4.052347                0.453441  \n",
       "...                 ...        ...               ...                     ...  \n",
       "306  38302      289.373        554          1.914484                0.460289  \n",
       "406  38308      204.226        481          2.355234                0.388773  \n",
       "902  38310      262.800        458          1.742770                0.379913  \n",
       "1502 38314      284.040        542          1.908182                0.464945  \n",
       "2616 38315      246.293        500          2.030102                0.504000  \n",
       "\n",
       "[5599 rows x 24 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Drop duplicate track rows, keeping only the first occurrence of when the track reached its top spot on the charts\n",
    "data_df = data_df.drop_duplicates(subset=[\"artist\",\"title\"],keep=\"last\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target column: 1 if it peaked in the top 5 else 0\n",
    "data_df[\"top_5\"] = data_df[\"peak_pos\"].apply(lambda x : 1 if x<=5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2289\n",
       "1     796\n",
       "Name: top_5, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df[\"top_5\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictive Modeling\n",
    "### 3.1. Data Split, Scaling, and SMOTE-NC\n",
    "Next, it was time to build some machine learning models. I used the macro-F1 score to compare models. First, I filtered the columns I wanted to use as features into variable **X** and set the target variable to **y**. I used a stratified split into a train and test set. Then I split the train set into 5 stratified folds for cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "X = data_df[[\"explicit\", \"danceability\",\"energy\",\"loudness\",\"speechiness\",\"acousticness\",\"valence\",\n",
    "             \"mean_sentiment\",\"std_sentiment\",\"duration_sec\",\"words_per_second\",\"unique_word_proportion\"]]\n",
    "X[\"explicit\"] = X[\"explicit\"].astype(\"category\")\n",
    "y = data_df[\"top_5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=5, stratify=y)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, v)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#We will scale all non-binary columns\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test\n",
    "\n",
    "X_train_scaled.loc[:,X_train_scaled.columns!=\"explicit\"] = scaler.fit_transform(X_train_scaled.loc[:,X_train_scaled.columns!=\"explicit\"])\n",
    "col_mean = scaler.mean_\n",
    "col_std = (scaler.var_)**.5\n",
    "\n",
    "X_test_scaled.loc[:,X_train_scaled.columns!=\"explicit\"] = (X_test.loc[:,X_train_scaled.columns!=\"explicit\"]-col_mean)/col_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I used the synthetic minority oversampling technique (SMOTE) which required installation of the following [module](https://pypi.org/project/imbalanced-learn/):\n",
    "\n",
    "```pip install imbalanced-learn```\n",
    "\n",
    "This technique generates additional samples from the non-majority classes so that the resulting data set has an equal representation for all classes. These additional samples are not simply copies of existing rows. Instead, the algorithm utilizes a nearest neighbors approach to synthesize new data points.\n",
    "\n",
    "A major challenge that arose was how to incorporate SMOTE into grid search and cross-fold validation. The synthetically generated training samples depend on the original training set. As a result, my decision to use 5 stratified folds essentially meant that 5 different SMOTE generated training sets would be needed. The below code solves this issue by generating a SMOTE training set for each of the 5 folds and saving the corresponding SMOTE training vs cross-validation indices into the **cv_indices** list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "sm = SMOTENC(categorical_features=[0], random_state= 17)\n",
    "\n",
    "X_train_custom = X_train_scaled.reset_index(drop=True)\n",
    "y_train_custom = y_train.reset_index(drop=True)\n",
    "num_rows_original = X_train_custom.shape[0]\n",
    "\n",
    "smote_indices = []\n",
    "cv_indices = []\n",
    "\n",
    "fold_num=0\n",
    "for train_index, cv_index in kf.split(X_train_custom,y_train_custom):\n",
    "    num_rows_fold_original = len(train_index)\n",
    "    X_train_smote_fold, y_train_smote_fold = sm.fit_sample(X_train_custom.iloc[train_index], \n",
    "                                                           y_train_custom.iloc[train_index])\n",
    "    X_train_smote_fold = X_train_smote_fold.iloc[num_rows_fold_original:]\n",
    "    y_train_smote_fold = y_train_smote_fold.iloc[num_rows_fold_original:]\n",
    "    X_train_custom = pd.concat([X_train_custom,X_train_smote_fold],ignore_index=True)\n",
    "    y_train_custom = pd.concat([y_train_custom,y_train_smote_fold],ignore_index=True)\n",
    "    if fold_num==0:\n",
    "        smote_indices.append([*range(num_rows_original,num_rows_original+X_train_smote_fold.shape[0])])\n",
    "    else:\n",
    "        last_row = smote_indices[-1][-1]\n",
    "        smote_indices.append([*range(last_row+1,last_row+1+X_train_smote_fold.shape[0])])\n",
    "    \n",
    "    \n",
    "    train_index_fold = np.append(train_index,smote_indices[fold_num])\n",
    "    cv_index_fold = cv_index\n",
    "    cv_indices.append((train_index_fold,cv_index_fold)) \n",
    "    \n",
    "    fold_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I ran SMOTE on the entire training set (without leaving any data out for cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1831\n",
       "0    1831\n",
       "Name: top_5, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_smote, y_train_smote = sm.fit_sample(X_train_scaled, y_train)\n",
    "y_train_smote.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([   0,    1,    3, ..., 3421, 3422, 3423]),\n",
       "                  array([   2,    4,   10,   15,   16,   17,   18,   20,   21,   40,   43,\n",
       "         50,   54,   58,   59,   64,   69,   74,   80,   84,   87,   90,\n",
       "         96,   98,  104,  112,  116,  119,  121,  130,  131,  144,  146,\n",
       "        152,  155,  157,  158,  162,  164,  167,  168,  171,  183,  184,\n",
       "        191,  195,  198,  199,  209,  214,  217,  220,  223,  226,  230,\n",
       "        235,  237,  238,  240,  246,  247,  250,  251,  254,  257,  263,\n",
       "        264,  267,  269,  270,  288,  295,  309,  310,  311,  315,  319,\n",
       "        320,  321,  3...\n",
       "       2309, 2310, 2320, 2322, 2325, 2338, 2346, 2349, 2357, 2361, 2363,\n",
       "       2365, 2370, 2375, 2377, 2383, 2384, 2388, 2389, 2395, 2397, 2400,\n",
       "       2403, 2406, 2407, 2419, 2430, 2432, 2442, 2446, 2457]))],\n",
       "             estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 3333,\n",
       "                               10000, 33333, 100000],\n",
       "                         'max_iter': [1000], 'penalty': ['l1', 'l2'],\n",
       "                         'random_state': [20], 'solver': ['liblinear']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_params = {\"penalty\":[\"l1\",\"l2\"], \n",
    "              \"C\":[.0001,.001,.01,.1,1,10,100,1000,3333,10000,33333,100000], \n",
    "              \"random_state\":[20],\n",
    "              \"solver\":[\"liblinear\"], \n",
    "              \"max_iter\":[1000]}\n",
    "log = LogisticRegression()\n",
    "log_grid = GridSearchCV(estimator=log,\n",
    "                        param_grid=log_params,\n",
    "                        scoring=\"f1_macro\",\n",
    "                        cv=cv_indices)\n",
    "log_grid.fit(X_train_custom, y_train_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01,\n",
       " 'max_iter': 1000,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': 20,\n",
       " 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5561362658267924"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. K-Nearest Neighbors\n",
    "While the above logistic regression was quite promising, I wanted to see if other ML models would result in better performance. I next built a KNN model. Given that I did not have that many features, I used all of them for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([   0,    1,    3, ..., 3421, 3422, 3423]),\n",
       "                  array([   2,    4,   10,   15,   16,   17,   18,   20,   21,   40,   43,\n",
       "         50,   54,   58,   59,   64,   69,   74,   80,   84,   87,   90,\n",
       "         96,   98,  104,  112,  116,  119,  121,  130,  131,  144,  146,\n",
       "        152,  155,  157,  158,  162,  164,  167,  168,  171,  183,  184,\n",
       "        191,  195,  198,  199,  209,  214,  217,  220,  223,  226,  230,\n",
       "        235,  237,  238,  240,  246,  247,  250,  251,  254,  257,  263,\n",
       "        264,  267,  269,  270,  288,  295,  309,  310,  311,  315,  319,\n",
       "        320,  321,  3...\n",
       "       2280, 2283, 2286, 2287, 2288, 2296, 2299, 2301, 2303, 2307, 2308,\n",
       "       2309, 2310, 2320, 2322, 2325, 2338, 2346, 2349, 2357, 2361, 2363,\n",
       "       2365, 2370, 2375, 2377, 2383, 2384, 2388, 2389, 2395, 2397, 2400,\n",
       "       2403, 2406, 2407, 2419, 2430, 2432, 2442, 2446, 2457]))],\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [2, 4, 8, 16, 32, 64, 128, 256, 512,\n",
       "                                         1024],\n",
       "                         'p': [1, 2], 'weights': ['uniform', 'distance']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_params = {\"n_neighbors\" : [2,4,8,16,32,64,128,256,512,1024],\n",
    "              \"weights\" : [\"uniform\", \"distance\"],\n",
    "              \"p\" : [1,2]}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(estimator=knn,\n",
    "                        param_grid=knn_params,\n",
    "                        scoring=\"f1_macro\",\n",
    "                        cv=cv_indices)\n",
    "knn_grid.fit(X_train_custom[log_features], y_train_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.530958495897352"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Support Vector Machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "[CV] C=0.0001, degree=2, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.0001, degree=2, kernel=poly, score=0.224, total=   0.6s\n",
      "[CV] C=0.0001, degree=2, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.0001, degree=2, kernel=poly, score=0.205, total=   0.5s\n",
      "[CV] C=0.0001, degree=2, kernel=poly .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... C=0.0001, degree=2, kernel=poly, score=0.426, total=   0.6s\n",
      "[CV] C=0.0001, degree=2, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=2, kernel=poly, score=0.205, total=   0.8s\n",
      "[CV] C=0.0001, degree=2, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=2, kernel=poly, score=0.205, total=   0.5s\n",
      "[CV] C=0.0001, degree=2, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=2, kernel=rbf, score=0.570, total=   0.8s\n",
      "[CV] C=0.0001, degree=2, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=2, kernel=rbf, score=0.550, total=   0.7s\n",
      "[CV] C=0.0001, degree=2, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=2, kernel=rbf, score=0.574, total=   0.8s\n",
      "[CV] C=0.0001, degree=2, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=2, kernel=rbf, score=0.561, total=   0.9s\n",
      "[CV] C=0.0001, degree=2, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=2, kernel=rbf, score=0.519, total=   0.8s\n",
      "[CV] C=0.0001, degree=3, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=3, kernel=poly, score=0.425, total=   0.5s\n",
      "[CV] C=0.0001, degree=3, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=3, kernel=poly, score=0.205, total=   0.6s\n",
      "[CV] C=0.0001, degree=3, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=3, kernel=poly, score=0.426, total=   0.5s\n",
      "[CV] C=0.0001, degree=3, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=3, kernel=poly, score=0.205, total=   0.5s\n",
      "[CV] C=0.0001, degree=3, kernel=poly .................................\n",
      "[CV] ..... C=0.0001, degree=3, kernel=poly, score=0.211, total=   0.6s\n",
      "[CV] C=0.0001, degree=3, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=3, kernel=rbf, score=0.570, total=   0.8s\n",
      "[CV] C=0.0001, degree=3, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=3, kernel=rbf, score=0.550, total=   0.8s\n",
      "[CV] C=0.0001, degree=3, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=3, kernel=rbf, score=0.574, total=   0.8s\n",
      "[CV] C=0.0001, degree=3, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=3, kernel=rbf, score=0.561, total=   0.7s\n",
      "[CV] C=0.0001, degree=3, kernel=rbf ..................................\n",
      "[CV] ...... C=0.0001, degree=3, kernel=rbf, score=0.519, total=   0.8s\n",
      "[CV] C=0.001, degree=2, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=2, kernel=poly, score=0.224, total=   0.5s\n",
      "[CV] C=0.001, degree=2, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=2, kernel=poly, score=0.205, total=   0.5s\n",
      "[CV] C=0.001, degree=2, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=2, kernel=poly, score=0.426, total=   0.5s\n",
      "[CV] C=0.001, degree=2, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=2, kernel=poly, score=0.205, total=   0.5s\n",
      "[CV] C=0.001, degree=2, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=2, kernel=poly, score=0.205, total=   0.5s\n",
      "[CV] C=0.001, degree=2, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=2, kernel=rbf, score=0.570, total=   0.9s\n",
      "[CV] C=0.001, degree=2, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=2, kernel=rbf, score=0.550, total=   0.8s\n",
      "[CV] C=0.001, degree=2, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=2, kernel=rbf, score=0.574, total=   0.7s\n",
      "[CV] C=0.001, degree=2, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=2, kernel=rbf, score=0.561, total=   0.8s\n",
      "[CV] C=0.001, degree=2, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=2, kernel=rbf, score=0.519, total=   0.8s\n",
      "[CV] C=0.001, degree=3, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=3, kernel=poly, score=0.212, total=   0.6s\n",
      "[CV] C=0.001, degree=3, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=3, kernel=poly, score=0.208, total=   0.5s\n",
      "[CV] C=0.001, degree=3, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=3, kernel=poly, score=0.283, total=   0.5s\n",
      "[CV] C=0.001, degree=3, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=3, kernel=poly, score=0.205, total=   0.8s\n",
      "[CV] C=0.001, degree=3, kernel=poly ..................................\n",
      "[CV] ...... C=0.001, degree=3, kernel=poly, score=0.214, total=   0.6s\n",
      "[CV] C=0.001, degree=3, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=3, kernel=rbf, score=0.570, total=   0.8s\n",
      "[CV] C=0.001, degree=3, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=3, kernel=rbf, score=0.550, total=   0.7s\n",
      "[CV] C=0.001, degree=3, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=3, kernel=rbf, score=0.574, total=   0.8s\n",
      "[CV] C=0.001, degree=3, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=3, kernel=rbf, score=0.561, total=   0.7s\n",
      "[CV] C=0.001, degree=3, kernel=rbf ...................................\n",
      "[CV] ....... C=0.001, degree=3, kernel=rbf, score=0.519, total=   0.8s\n",
      "[CV] C=0.01, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=2, kernel=poly, score=0.277, total=   0.5s\n",
      "[CV] C=0.01, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=2, kernel=poly, score=0.247, total=   0.7s\n",
      "[CV] C=0.01, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=2, kernel=poly, score=0.264, total=   0.7s\n",
      "[CV] C=0.01, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=2, kernel=poly, score=0.245, total=   0.7s\n",
      "[CV] C=0.01, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=2, kernel=poly, score=0.252, total=   0.5s\n",
      "[CV] C=0.01, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=2, kernel=rbf, score=0.570, total=   0.8s\n",
      "[CV] C=0.01, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=2, kernel=rbf, score=0.550, total=   0.9s\n",
      "[CV] C=0.01, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=2, kernel=rbf, score=0.574, total=   0.8s\n",
      "[CV] C=0.01, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=2, kernel=rbf, score=0.561, total=   0.8s\n",
      "[CV] C=0.01, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=2, kernel=rbf, score=0.519, total=   0.8s\n",
      "[CV] C=0.01, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=3, kernel=poly, score=0.311, total=   0.5s\n",
      "[CV] C=0.01, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=3, kernel=poly, score=0.263, total=   0.5s\n",
      "[CV] C=0.01, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=3, kernel=poly, score=0.252, total=   0.5s\n",
      "[CV] C=0.01, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=3, kernel=poly, score=0.241, total=   0.5s\n",
      "[CV] C=0.01, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=0.01, degree=3, kernel=poly, score=0.252, total=   0.5s\n",
      "[CV] C=0.01, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=3, kernel=rbf, score=0.570, total=   0.7s\n",
      "[CV] C=0.01, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=3, kernel=rbf, score=0.550, total=   0.7s\n",
      "[CV] C=0.01, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=3, kernel=rbf, score=0.574, total=   0.8s\n",
      "[CV] C=0.01, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=3, kernel=rbf, score=0.561, total=   0.7s\n",
      "[CV] C=0.01, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=0.01, degree=3, kernel=rbf, score=0.519, total=   0.7s\n",
      "[CV] C=0.1, degree=2, kernel=poly ....................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ C=0.1, degree=2, kernel=poly, score=0.472, total=   0.4s\n",
      "[CV] C=0.1, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=2, kernel=poly, score=0.501, total=   0.5s\n",
      "[CV] C=0.1, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=2, kernel=poly, score=0.532, total=   0.5s\n",
      "[CV] C=0.1, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=2, kernel=poly, score=0.466, total=   0.5s\n",
      "[CV] C=0.1, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=2, kernel=poly, score=0.510, total=   0.5s\n",
      "[CV] C=0.1, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=2, kernel=rbf, score=0.543, total=   0.7s\n",
      "[CV] C=0.1, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=2, kernel=rbf, score=0.557, total=   0.8s\n",
      "[CV] C=0.1, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=2, kernel=rbf, score=0.588, total=   0.7s\n",
      "[CV] C=0.1, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=2, kernel=rbf, score=0.548, total=   0.7s\n",
      "[CV] C=0.1, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=2, kernel=rbf, score=0.559, total=   0.6s\n",
      "[CV] C=0.1, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=3, kernel=poly, score=0.457, total=   0.5s\n",
      "[CV] C=0.1, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=3, kernel=poly, score=0.457, total=   0.5s\n",
      "[CV] C=0.1, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=3, kernel=poly, score=0.487, total=   0.5s\n",
      "[CV] C=0.1, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=3, kernel=poly, score=0.408, total=   0.5s\n",
      "[CV] C=0.1, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=0.1, degree=3, kernel=poly, score=0.491, total=   0.5s\n",
      "[CV] C=0.1, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=3, kernel=rbf, score=0.543, total=   1.0s\n",
      "[CV] C=0.1, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=3, kernel=rbf, score=0.557, total=   0.9s\n",
      "[CV] C=0.1, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=3, kernel=rbf, score=0.588, total=   0.7s\n",
      "[CV] C=0.1, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=3, kernel=rbf, score=0.548, total=   0.7s\n",
      "[CV] C=0.1, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=0.1, degree=3, kernel=rbf, score=0.559, total=   0.6s\n",
      "[CV] C=1, degree=2, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=2, kernel=poly, score=0.523, total=   0.5s\n",
      "[CV] C=1, degree=2, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=2, kernel=poly, score=0.525, total=   0.5s\n",
      "[CV] C=1, degree=2, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=2, kernel=poly, score=0.542, total=   0.5s\n",
      "[CV] C=1, degree=2, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=2, kernel=poly, score=0.510, total=   0.5s\n",
      "[CV] C=1, degree=2, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=2, kernel=poly, score=0.547, total=   0.6s\n",
      "[CV] C=1, degree=2, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=2, kernel=rbf, score=0.535, total=   0.7s\n",
      "[CV] C=1, degree=2, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=2, kernel=rbf, score=0.524, total=   0.7s\n",
      "[CV] C=1, degree=2, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=2, kernel=rbf, score=0.587, total=   0.7s\n",
      "[CV] C=1, degree=2, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=2, kernel=rbf, score=0.521, total=   0.7s\n",
      "[CV] C=1, degree=2, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=2, kernel=rbf, score=0.531, total=   0.7s\n",
      "[CV] C=1, degree=3, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=3, kernel=poly, score=0.518, total=   0.6s\n",
      "[CV] C=1, degree=3, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=3, kernel=poly, score=0.527, total=   0.6s\n",
      "[CV] C=1, degree=3, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=3, kernel=poly, score=0.506, total=   0.6s\n",
      "[CV] C=1, degree=3, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=3, kernel=poly, score=0.476, total=   0.7s\n",
      "[CV] C=1, degree=3, kernel=poly ......................................\n",
      "[CV] .......... C=1, degree=3, kernel=poly, score=0.512, total=   0.7s\n",
      "[CV] C=1, degree=3, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=3, kernel=rbf, score=0.535, total=   0.7s\n",
      "[CV] C=1, degree=3, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=3, kernel=rbf, score=0.524, total=   0.6s\n",
      "[CV] C=1, degree=3, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=3, kernel=rbf, score=0.587, total=   0.7s\n",
      "[CV] C=1, degree=3, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=3, kernel=rbf, score=0.521, total=   0.6s\n",
      "[CV] C=1, degree=3, kernel=rbf .......................................\n",
      "[CV] ........... C=1, degree=3, kernel=rbf, score=0.531, total=   0.7s\n",
      "[CV] C=10, degree=2, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=2, kernel=poly, score=0.504, total=   1.0s\n",
      "[CV] C=10, degree=2, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=2, kernel=poly, score=0.505, total=   1.1s\n",
      "[CV] C=10, degree=2, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=2, kernel=poly, score=0.547, total=   1.1s\n",
      "[CV] C=10, degree=2, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=2, kernel=poly, score=0.496, total=   1.0s\n",
      "[CV] C=10, degree=2, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=2, kernel=poly, score=0.552, total=   1.1s\n",
      "[CV] C=10, degree=2, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=2, kernel=rbf, score=0.546, total=   1.0s\n",
      "[CV] C=10, degree=2, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=2, kernel=rbf, score=0.525, total=   1.1s\n",
      "[CV] C=10, degree=2, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=2, kernel=rbf, score=0.599, total=   0.9s\n",
      "[CV] C=10, degree=2, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=2, kernel=rbf, score=0.522, total=   1.0s\n",
      "[CV] C=10, degree=2, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=2, kernel=rbf, score=0.535, total=   1.0s\n",
      "[CV] C=10, degree=3, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=3, kernel=poly, score=0.528, total=   2.6s\n",
      "[CV] C=10, degree=3, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=3, kernel=poly, score=0.513, total=   1.7s\n",
      "[CV] C=10, degree=3, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=3, kernel=poly, score=0.521, total=   2.3s\n",
      "[CV] C=10, degree=3, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=3, kernel=poly, score=0.492, total=   2.6s\n",
      "[CV] C=10, degree=3, kernel=poly .....................................\n",
      "[CV] ......... C=10, degree=3, kernel=poly, score=0.509, total=   2.5s\n",
      "[CV] C=10, degree=3, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=3, kernel=rbf, score=0.546, total=   1.2s\n",
      "[CV] C=10, degree=3, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=3, kernel=rbf, score=0.525, total=   1.3s\n",
      "[CV] C=10, degree=3, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=3, kernel=rbf, score=0.599, total=   1.1s\n",
      "[CV] C=10, degree=3, kernel=rbf ......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... C=10, degree=3, kernel=rbf, score=0.522, total=   1.4s\n",
      "[CV] C=10, degree=3, kernel=rbf ......................................\n",
      "[CV] .......... C=10, degree=3, kernel=rbf, score=0.535, total=   1.1s\n",
      "[CV] C=100, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=2, kernel=poly, score=0.505, total=   4.6s\n",
      "[CV] C=100, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=2, kernel=poly, score=0.509, total=   3.6s\n",
      "[CV] C=100, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=2, kernel=poly, score=0.562, total=   5.3s\n",
      "[CV] C=100, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=2, kernel=poly, score=0.499, total=   4.4s\n",
      "[CV] C=100, degree=2, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=2, kernel=poly, score=0.537, total=   4.3s\n",
      "[CV] C=100, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=2, kernel=rbf, score=0.544, total=   2.8s\n",
      "[CV] C=100, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=2, kernel=rbf, score=0.521, total=   2.7s\n",
      "[CV] C=100, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=2, kernel=rbf, score=0.599, total=   2.9s\n",
      "[CV] C=100, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=2, kernel=rbf, score=0.517, total=   2.6s\n",
      "[CV] C=100, degree=2, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=2, kernel=rbf, score=0.531, total=   2.8s\n",
      "[CV] C=100, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=3, kernel=poly, score=0.519, total=  18.4s\n",
      "[CV] C=100, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=3, kernel=poly, score=0.520, total=  16.5s\n",
      "[CV] C=100, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=3, kernel=poly, score=0.516, total=  14.6s\n",
      "[CV] C=100, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=3, kernel=poly, score=0.487, total=  15.8s\n",
      "[CV] C=100, degree=3, kernel=poly ....................................\n",
      "[CV] ........ C=100, degree=3, kernel=poly, score=0.510, total=  16.0s\n",
      "[CV] C=100, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=3, kernel=rbf, score=0.544, total=   2.7s\n",
      "[CV] C=100, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=3, kernel=rbf, score=0.521, total=   3.1s\n",
      "[CV] C=100, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=3, kernel=rbf, score=0.599, total=   2.8s\n",
      "[CV] C=100, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=3, kernel=rbf, score=0.517, total=   2.4s\n",
      "[CV] C=100, degree=3, kernel=rbf .....................................\n",
      "[CV] ......... C=100, degree=3, kernel=rbf, score=0.531, total=   2.5s\n",
      "[CV] C=1000, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=2, kernel=poly, score=0.507, total=  34.0s\n",
      "[CV] C=1000, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=2, kernel=poly, score=0.512, total=  32.0s\n",
      "[CV] C=1000, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=2, kernel=poly, score=0.564, total=  41.0s\n",
      "[CV] C=1000, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=2, kernel=poly, score=0.499, total=  34.5s\n",
      "[CV] C=1000, degree=2, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=2, kernel=poly, score=0.539, total=  28.5s\n",
      "[CV] C=1000, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=2, kernel=rbf, score=0.521, total=   5.9s\n",
      "[CV] C=1000, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=2, kernel=rbf, score=0.528, total=   5.8s\n",
      "[CV] C=1000, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=2, kernel=rbf, score=0.602, total=   6.6s\n",
      "[CV] C=1000, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=2, kernel=rbf, score=0.487, total=   5.8s\n",
      "[CV] C=1000, degree=2, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=2, kernel=rbf, score=0.526, total=   6.3s\n",
      "[CV] C=1000, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=3, kernel=poly, score=0.515, total= 4.6min\n",
      "[CV] C=1000, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=3, kernel=poly, score=0.519, total= 2.5min\n",
      "[CV] C=1000, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=3, kernel=poly, score=0.531, total= 2.3min\n",
      "[CV] C=1000, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=3, kernel=poly, score=0.501, total= 2.9min\n",
      "[CV] C=1000, degree=3, kernel=poly ...................................\n",
      "[CV] ....... C=1000, degree=3, kernel=poly, score=0.514, total= 2.3min\n",
      "[CV] C=1000, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=3, kernel=rbf, score=0.521, total=   6.4s\n",
      "[CV] C=1000, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=3, kernel=rbf, score=0.528, total=   7.3s\n",
      "[CV] C=1000, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=3, kernel=rbf, score=0.602, total=   7.5s\n",
      "[CV] C=1000, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=3, kernel=rbf, score=0.487, total=   6.2s\n",
      "[CV] C=1000, degree=3, kernel=rbf ....................................\n",
      "[CV] ........ C=1000, degree=3, kernel=rbf, score=0.526, total=   6.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed: 22.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([   0,    1,    3, ..., 3421, 3422, 3423]),\n",
       "                  array([   2,    4,   10,   15,   16,   17,   18,   20,   21,   40,   43,\n",
       "         50,   54,   58,   59,   64,   69,   74,   80,   84,   87,   90,\n",
       "         96,   98,  104,  112,  116,  119,  121,  130,  131,  144,  146,\n",
       "        152,  155,  157,  158,  162,  164,  167,  168,  171,  183,  184,\n",
       "        191,  195,  198,  199,  209,  214,  217,  220,  223,  226,  230,\n",
       "        235,  237,  238,  240,  246,  247,  250,  251,  254,  257,  263,\n",
       "        264,  267,  269,  270,  288,  295,  309,  310,  311,  315,  319,\n",
       "        320,  321,  3...\n",
       "       2280, 2283, 2286, 2287, 2288, 2296, 2299, 2301, 2303, 2307, 2308,\n",
       "       2309, 2310, 2320, 2322, 2325, 2338, 2346, 2349, 2357, 2361, 2363,\n",
       "       2365, 2370, 2375, 2377, 2383, 2384, 2388, 2389, 2395, 2397, 2400,\n",
       "       2403, 2406, 2407, 2419, 2430, 2432, 2442, 2446, 2457]))],\n",
       "             estimator=SVC(),\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
       "                         'degree': [2, 3], 'kernel': ['poly', 'rbf']},\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm_params = {\"C\":[.0001,.001,.01,.1,1,10,100,1000], \n",
    "              \"kernel\":[\"poly\",\"rbf\"],\n",
    "              \"degree\":[2,3]}\n",
    "svm = SVC()\n",
    "svm_grid = GridSearchCV(estimator=svm,\n",
    "                        param_grid=svm_params,\n",
    "                        scoring=\"f1_macro\",\n",
    "                        cv=cv_indices, \n",
    "                        verbose=3)\n",
    "svm_grid.fit(X_train_custom, y_train_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'degree': 2, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5590538164185677"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   0.6s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   0.7s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.532, total=   0.6s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.473, total=   0.8s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.519, total=   1.2s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   1.0s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   0.7s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   0.6s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.473, total=   0.7s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.519, total=   0.7s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.517, total=   0.6s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.550, total=   0.9s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.532, total=   0.6s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.473, total=   0.6s\n",
      "[CV] max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.519, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.532, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.473, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.519, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   0.6s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   0.6s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.473, total=   0.7s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.519, total=   0.6s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.517, total=   1.0s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.550, total=   0.8s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.532, total=   0.8s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.473, total=   0.6s\n",
      "[CV] max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.519, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.536, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.546, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.488, total=   0.8s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.533, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.536, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.558, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.488, total=   0.4s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.533, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.536, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.547, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.488, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   0.5s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   0.8s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   0.8s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.532, total=   1.1s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.473, total=   1.0s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.519, total=   0.8s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   0.7s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   0.7s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.473, total=   1.1s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.519, total=   0.8s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.517, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.550, total=   0.7s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.532, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.473, total=   0.6s\n",
      "[CV] max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.519, total=   0.7s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.507, total=   1.3s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.515, total=   0.9s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   0.9s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.451, total=   1.1s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.480, total=   0.8s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.507, total=   1.0s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   1.0s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   1.1s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.451, total=   1.2s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.480, total=   1.2s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.507, total=   1.0s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.515, total=   1.0s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.517, total=   0.9s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.451, total=   1.0s\n",
      "[CV] max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.480, total=   0.9s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.509, total=   0.8s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   0.9s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.529, total=   0.7s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.459, total=   0.7s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.498, total=   1.2s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.509, total=   0.9s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   0.8s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   1.1s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.459, total=   0.9s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.498, total=   0.8s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.509, total=   0.8s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.517, total=   0.8s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.532, total=   0.8s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.459, total=   0.7s\n",
      "[CV] max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.498, total=   1.3s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.518, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.525, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.518, total=   1.2s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.439, total=   1.2s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.458, total=   1.4s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.518, total=   1.4s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.525, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.518, total=   1.3s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.439, total=   1.5s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.458, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.518, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.525, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.518, total=   1.1s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.439, total=   1.2s\n",
      "[CV] max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.458, total=   1.4s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=2, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.528, total=   0.8s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.562, total=   1.0s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   0.8s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.1s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   1.0s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   0.9s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.556, total=   0.8s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   1.3s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.502, total=   0.9s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.528, total=   0.8s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   0.8s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   0.9s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.543, total=   1.2s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.502, total=   1.0s\n",
      "[CV] max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.522, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.528, total=   0.9s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.562, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   1.0s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   1.0s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.556, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.502, total=   0.9s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.528, total=   0.9s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   0.9s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   0.9s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.543, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.502, total=   0.8s\n",
      "[CV] max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.522, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.532, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.543, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.580, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.508, total=   0.7s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.530, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.540, total=   0.8s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.538, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.599, total=   0.5s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.491, total=   0.5s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.533, total=   1.1s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.536, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.545, total=   0.8s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.579, total=   0.7s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.509, total=   0.6s\n",
      "[CV] max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.536, total=   0.5s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.528, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.562, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   0.8s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.2s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   1.0s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.532, total=   1.0s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.556, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.502, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.528, total=   1.2s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   0.8s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.0s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.543, total=   1.0s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.502, total=   0.9s\n",
      "[CV] max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.522, total=   1.0s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.521, total=   1.6s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.556, total=   1.5s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.552, total=   1.2s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.485, total=   1.5s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.483, total=   1.3s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.526, total=   1.4s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.560, total=   1.2s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.552, total=   1.4s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.484, total=   1.6s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.491, total=   1.5s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.512, total=   1.4s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.551, total=   2.1s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.561, total=   1.4s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.482, total=   1.5s\n",
      "[CV] max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.496, total=   1.3s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.532, total=   1.5s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   1.2s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.563, total=   1.0s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.487, total=   1.2s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.503, total=   1.3s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.535, total=   1.4s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.548, total=   1.6s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   1.4s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.491, total=   1.4s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.503, total=   1.1s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.2s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.556, total=   1.1s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.555, total=   1.3s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.492, total=   1.3s\n",
      "[CV] max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.500, total=   1.1s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.516, total=   2.0s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.557, total=   1.9s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.556, total=   2.0s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.478, total=   1.7s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.475, total=   2.5s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   1.9s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   2.0s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.555, total=   1.9s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.478, total=   1.8s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.476, total=   1.9s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.515, total=   2.0s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.556, total=   1.8s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.552, total=   1.9s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.476, total=   2.0s\n",
      "[CV] max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.477, total=   1.9s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.3s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.3s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.3s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=4, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   1.3s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.564, total=   1.3s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.578, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.511, total=   1.5s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.547, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.569, total=   1.3s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.4s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   1.1s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.563, total=   1.3s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.505, total=   1.2s\n",
      "[CV] max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.551, total=   1.2s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   1.2s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.564, total=   1.4s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.578, total=   1.4s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.511, total=   1.2s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.547, total=   1.3s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.4s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   1.5s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.569, total=   1.3s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.8s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   1.7s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.7s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   1.5s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.563, total=   1.5s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.505, total=   1.3s\n",
      "[CV] max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.551, total=   1.4s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.549, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.603, total=   0.8s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   1.0s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   0.9s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.555, total=   0.8s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.556, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.599, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   0.9s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.512, total=   0.8s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.547, total=   1.1s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.585, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.515, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.504, total=   0.7s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.564, total=   1.3s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.578, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.511, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.547, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.3s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   1.3s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.569, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.3s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   1.1s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.563, total=   1.1s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.505, total=   1.4s\n",
      "[CV] max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.551, total=   1.2s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.528, total=   2.2s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.580, total=   1.9s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.570, total=   2.2s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.505, total=   1.9s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.537, total=   2.0s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.556, total=   2.1s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.586, total=   2.0s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.581, total=   2.0s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.493, total=   2.6s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.531, total=   1.9s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.536, total=   2.0s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.595, total=   1.8s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.560, total=   2.1s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.520, total=   2.6s\n",
      "[CV] max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.544, total=   2.1s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.545, total=   2.0s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   2.1s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.564, total=   1.9s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.506, total=   1.9s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.548, total=   1.7s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.555, total=   1.9s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.564, total=   2.0s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.569, total=   1.9s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.497, total=   1.7s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   2.0s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.7s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.563, total=   2.0s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.560, total=   1.9s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.508, total=   1.8s\n",
      "[CV] max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.540, total=   2.3s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   3.4s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.567, total=   3.1s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.557, total=   3.2s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.503, total=   3.3s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.530, total=   3.0s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.535, total=   3.2s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.579, total=   2.9s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   3.2s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.506, total=   3.3s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   3.0s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.542, total=   3.0s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.567, total=   3.3s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.566, total=   3.0s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.508, total=   3.1s\n",
      "[CV] max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.530, total=   3.0s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=8, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.547, total=   2.0s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.568, total=   1.7s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.521, total=   1.8s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.526, total=   1.7s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.548, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.578, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.596, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.534, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.9s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   1.7s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.590, total=   1.6s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.7s\n",
      "[CV] max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.544, total=   1.7s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.547, total=   2.2s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   2.3s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.568, total=   1.8s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.521, total=   1.6s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.526, total=   1.7s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.548, total=   1.7s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.578, total=   1.5s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.596, total=   1.7s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.534, total=   1.6s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.5s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   1.6s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.590, total=   1.5s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.6s\n",
      "[CV] max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.544, total=   1.7s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.550, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.546, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.627, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.513, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.514, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   1.0s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.530, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.610, total=   1.0s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.530, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.498, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.564, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.553, total=   1.0s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.621, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.545, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.526, total=   0.9s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.547, total=   1.6s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   1.7s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.568, total=   1.6s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.521, total=   1.6s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.526, total=   1.7s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.548, total=   1.6s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.578, total=   1.5s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.596, total=   1.5s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.534, total=   1.5s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.7s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   2.4s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.590, total=   2.0s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.533, total=   1.7s\n",
      "[CV] max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.544, total=   2.2s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.555, total=   2.8s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.563, total=   3.0s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.587, total=   3.1s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   3.1s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.537, total=   2.6s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.554, total=   2.7s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   2.8s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.595, total=   2.9s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.520, total=   2.6s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.537, total=   2.6s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.553, total=   2.5s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.552, total=   2.5s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.589, total=   2.5s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.523, total=   2.6s\n",
      "[CV] max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   2.5s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.551, total=   2.5s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.553, total=   2.6s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.595, total=   2.4s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.527, total=   2.4s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.538, total=   2.4s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.571, total=   2.7s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.566, total=   2.3s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.608, total=   2.7s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.506, total=   2.4s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   2.2s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.565, total=   2.3s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.566, total=   2.0s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.598, total=   2.2s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.522, total=   2.1s\n",
      "[CV] max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.546, total=   2.0s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.574, total=   4.2s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.552, total=   4.0s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.572, total=   4.1s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.518, total=   4.3s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.546, total=   4.6s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.572, total=   4.4s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.553, total=   3.8s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.591, total=   4.2s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.512, total=   4.2s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.541, total=   4.2s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.570, total=   3.9s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.571, total=   3.4s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.556, total=   3.7s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.524, total=   3.9s\n",
      "[CV] max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.534, total=   3.7s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=16, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.542, total=   1.7s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   1.6s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.582, total=   1.8s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.508, total=   1.8s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   2.0s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.7s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.6s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.6s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.9s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.5s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.6s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.8s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.6s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.542, total=   2.0s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   2.1s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.582, total=   1.9s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.508, total=   2.6s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.9s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.9s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.7s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.9s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.9s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.7s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.5s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.7s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.9s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.513, total=   1.1s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.554, total=   1.2s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.597, total=   1.0s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.511, total=   1.2s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.523, total=   1.0s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   1.0s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   1.3s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.620, total=   0.9s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.546, total=   0.9s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.488, total=   0.9s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.575, total=   0.8s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.545, total=   0.8s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.601, total=   1.2s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.526, total=   0.9s\n",
      "[CV] max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.523, total=   0.9s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.542, total=   1.8s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   2.3s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.582, total=   1.9s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.508, total=   2.0s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   2.1s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   2.1s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.9s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   2.0s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.9s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.8s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.7s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.7s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.8s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.9s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.551, total=   3.3s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.566, total=   2.6s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.599, total=   3.0s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   3.1s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.541, total=   3.4s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   3.0s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.554, total=   2.8s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   2.8s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   2.9s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.539, total=   2.8s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.578, total=   3.4s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   4.0s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.595, total=   3.4s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.524, total=   3.8s\n",
      "[CV] max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   3.1s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.554, total=   4.9s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.548, total=   3.3s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.599, total=   3.3s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.515, total=   3.1s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.532, total=   3.6s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.545, total=   3.1s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   2.3s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.591, total=   2.3s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   2.4s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   2.3s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   2.5s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.571, total=   3.7s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.611, total=   2.6s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.521, total=   2.4s\n",
      "[CV] max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.7s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   5.4s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   5.4s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   5.4s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.523, total=   4.7s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   4.7s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   4.4s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.577, total=   4.1s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.592, total=   4.1s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.523, total=   4.4s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.538, total=   4.0s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.565, total=   4.2s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   4.2s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.583, total=   4.3s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   4.5s\n",
      "[CV] max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.541, total=   4.4s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.2s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=32, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.8s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.6s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.7s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.8s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.6s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.6s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.5s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.6s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.7s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.5s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.6s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.7s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.9s\n",
      "[CV] max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.9s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.9s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.9s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.9s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.7s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.8s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.6s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.5s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.7s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.7s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.6s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.9s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.5s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.5s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.5s\n",
      "[CV] max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   1.0s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   0.9s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.587, total=   0.9s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.513, total=   1.0s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   1.1s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.558, total=   0.9s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.620, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   0.9s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.488, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.575, total=   1.0s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.545, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.601, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.526, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.523, total=   0.8s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.9s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.7s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.7s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.8s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.9s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.9s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.7s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.5s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.7s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.545, total=   3.4s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.566, total=   2.9s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.599, total=   2.7s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   2.9s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   2.7s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   2.9s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.554, total=   2.6s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   2.8s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   2.7s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.539, total=   2.8s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.578, total=   2.6s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.8s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.595, total=   2.7s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.524, total=   2.8s\n",
      "[CV] max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   2.7s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.553, total=   2.6s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.548, total=   2.3s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.601, total=   2.5s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.515, total=   2.5s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.526, total=   2.5s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   2.3s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   2.2s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.591, total=   2.4s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   2.3s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   2.3s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   2.5s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.571, total=   2.4s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.611, total=   2.3s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.521, total=   2.7s\n",
      "[CV] max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.5s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   4.4s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   4.0s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   4.3s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.519, total=   5.6s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   4.2s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   4.1s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.577, total=   4.2s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.592, total=   4.0s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.523, total=   4.6s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.538, total=   4.1s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.565, total=   4.5s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   3.9s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.583, total=   3.9s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   4.1s\n",
      "[CV] max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.541, total=   3.9s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=64, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.8s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.6s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.7s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.7s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.7s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.8s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.5s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.6s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.7s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.7s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.5s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.6s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.7s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.5s\n",
      "[CV] max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.5s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.8s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.6s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.6s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.9s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.9s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.8s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.6s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.8s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.7s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.7s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.4s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.6s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.8s\n",
      "[CV] max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.5s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.587, total=   1.0s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.513, total=   1.0s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.558, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   0.8s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.620, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   1.1s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.488, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.575, total=   0.8s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.545, total=   0.8s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.601, total=   1.0s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.526, total=   1.0s\n",
      "[CV] max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.523, total=   0.9s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.8s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.6s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.8s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.9s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.9s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.7s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.6s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.9s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   2.0s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   2.7s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.9s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   2.5s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   2.2s\n",
      "[CV] max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   2.4s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.545, total=   3.4s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.566, total=   2.8s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.599, total=   3.9s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   3.0s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   3.0s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   3.0s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.554, total=   2.9s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   3.2s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   3.3s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.539, total=   2.9s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.578, total=   2.8s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.8s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.595, total=   2.7s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.524, total=   2.9s\n",
      "[CV] max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   2.7s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.553, total=   2.8s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.548, total=   2.4s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.601, total=   2.4s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.515, total=   2.8s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.526, total=   2.8s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   3.5s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   2.8s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.591, total=   2.7s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   3.0s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   2.6s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   2.8s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.571, total=   2.6s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.611, total=   2.3s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.521, total=   2.7s\n",
      "[CV] max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.4s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   5.0s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   4.2s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   4.5s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.519, total=   5.1s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   4.7s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   4.4s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.577, total=   4.1s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.592, total=   4.5s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.523, total=   5.0s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.538, total=   4.6s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.565, total=   4.2s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   4.4s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.583, total=   4.2s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   4.4s\n",
      "[CV] max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.541, total=   4.3s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.2s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=128, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   2.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   2.0s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.7s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   2.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.8s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   2.5s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   2.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   2.0s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   2.0s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.7s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.6s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.9s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.7s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.8s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.8s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   1.7s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.6s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.8s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.7s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.7s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.9s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.9s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.7s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.9s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.6s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.6s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.7s\n",
      "[CV] max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=log2, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.9s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.517, total=   1.2s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.560, total=   1.0s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.587, total=   1.1s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.513, total=   1.3s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   1.3s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.558, total=   0.9s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   0.9s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.620, total=   1.0s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.547, total=   1.2s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.488, total=   0.9s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.575, total=   1.0s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.545, total=   0.8s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.601, total=   0.9s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.526, total=   0.9s\n",
      "[CV] max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.1, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.523, total=   1.0s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.544, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.561, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.581, total=   2.0s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.504, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.522, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.550, total=   1.9s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   1.5s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.616, total=   1.6s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.524, total=   1.6s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.508, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.539, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.549, total=   1.4s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.605, total=   1.7s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.527, total=   1.6s\n",
      "[CV] max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.25, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   1.5s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.545, total=   3.0s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.566, total=   2.6s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.599, total=   2.8s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.524, total=   2.8s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   3.1s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.559, total=   2.9s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.554, total=   3.7s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.568, total=   3.4s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   3.1s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.539, total=   2.8s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.578, total=   2.8s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.9s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.595, total=   2.7s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.524, total=   2.7s\n",
      "[CV] max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=0.5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.535, total=   2.5s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.553, total=   2.6s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.548, total=   2.3s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.601, total=   2.4s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.515, total=   2.7s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.526, total=   2.4s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.544, total=   2.5s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   2.3s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.591, total=   2.4s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.517, total=   2.3s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.515, total=   2.3s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.558, total=   2.4s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.571, total=   2.1s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.611, total=   2.3s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.521, total=   2.4s\n",
      "[CV] max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=5, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.538, total=   2.5s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   5.2s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.577, total=   4.4s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.575, total=   4.2s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.519, total=   4.6s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=1, n_estimators=100, random_state=10, score=0.539, total=   4.6s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.562, total=   4.2s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.577, total=   4.1s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.592, total=   4.1s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.523, total=   4.5s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=3, n_estimators=100, random_state=10, score=0.538, total=   4.6s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.565, total=   4.8s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.559, total=   4.4s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.583, total=   4.0s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.531, total=   4.3s\n",
      "[CV] max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=10, min_samples_leaf=5, n_estimators=100, random_state=10, score=0.541, total=   4.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=1, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=3, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n",
      "[CV] max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10 \n",
      "[CV]  max_depth=None, max_features=25, min_samples_leaf=5, n_estimators=100, random_state=10, score=nan, total=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 392, in fit\n",
      "    for i, t in enumerate(trees))\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1004, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 835, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 754, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 209, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 590, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 256, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 168, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 894, in fit\n",
      "    X_idx_sorted=X_idx_sorted)\n",
      "  File \"C:\\Users\\Sahil\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 279, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  FitFailedWarning)\n",
      "[Parallel(n_jobs=1)]: Done 960 out of 960 | elapsed: 26.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=[(array([   0,    1,    3, ..., 3421, 3422, 3423]),\n",
       "                  array([   2,    4,   10,   15,   16,   17,   18,   20,   21,   40,   43,\n",
       "         50,   54,   58,   59,   64,   69,   74,   80,   84,   87,   90,\n",
       "         96,   98,  104,  112,  116,  119,  121,  130,  131,  144,  146,\n",
       "        152,  155,  157,  158,  162,  164,  167,  168,  171,  183,  184,\n",
       "        191,  195,  198,  199,  209,  214,  217,  220,  223,  226,  230,\n",
       "        235,  237,  238,  240,  246,  247,  250,  251,  254,  257,  263,\n",
       "        264,  267,  269,  270,  288,  295,  309,  310,  311,  315,  319,\n",
       "        320,  321,  3...\n",
       "       2309, 2310, 2320, 2322, 2325, 2338, 2346, 2349, 2357, 2361, 2363,\n",
       "       2365, 2370, 2375, 2377, 2383, 2384, 2388, 2389, 2395, 2397, 2400,\n",
       "       2403, 2406, 2407, 2419, 2430, 2432, 2442, 2446, 2457]))],\n",
       "             estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [2, 4, 8, 16, 32, 64, 128, None],\n",
       "                         'max_features': ['sqrt', 'log2', 0.1, 0.25, 0.5, 5, 10,\n",
       "                                          25],\n",
       "                         'min_samples_leaf': [1, 3, 5], 'n_estimators': [100],\n",
       "                         'random_state': [10]},\n",
       "             scoring='f1_macro', verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_params = {\"n_estimators\" : [100], \n",
    "             \"max_depth\" : [2,4,8,16,32,64,128,None], \n",
    "             \"max_features\" : [\"sqrt\", \"log2\", .1, .25, .5, 5, 10, 25], \n",
    "             \"min_samples_leaf\" : [1,3,5],\n",
    "             \"random_state\" : [10]}\n",
    "rf = RandomForestClassifier()\n",
    "rf_grid = GridSearchCV(estimator=rf,\n",
    "                       param_grid=rf_params,\n",
    "                       scoring=\"f1_macro\",\n",
    "                       cv=cv_indices, \n",
    "                       verbose=3)\n",
    "rf_grid.fit(X_train_custom, y_train_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 16,\n",
       " 'max_features': 0.1,\n",
       " 'min_samples_leaf': 5,\n",
       " 'n_estimators': 100,\n",
       " 'random_state': 10}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5615439525222539"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. Model Selection and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results of the above models are summarized in the table below (ordered from best to worst performance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>optimized_parameters</th>\n",
       "      <th>macro-F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>{'max_depth': 16, 'max_features': 0.1, 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 10}</td>\n",
       "      <td>0.561544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>{'C': 0.1, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.559054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>{'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 20, 'solver': 'liblinear'}</td>\n",
       "      <td>0.556136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>{'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}</td>\n",
       "      <td>0.530958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  \\\n",
       "3           Random Forest   \n",
       "2  Support Vector Machine   \n",
       "0     Logistic Regression   \n",
       "1     K-Nearest Neighbors   \n",
       "\n",
       "                                                                                     optimized_parameters  \\\n",
       "3  {'max_depth': 16, 'max_features': 0.1, 'min_samples_leaf': 5, 'n_estimators': 100, 'random_state': 10}   \n",
       "2                                                                {'C': 0.1, 'degree': 2, 'kernel': 'rbf'}   \n",
       "0               {'C': 0.01, 'max_iter': 1000, 'penalty': 'l2', 'random_state': 20, 'solver': 'liblinear'}   \n",
       "1                                                        {'n_neighbors': 2, 'p': 2, 'weights': 'uniform'}   \n",
       "\n",
       "   macro-F1  \n",
       "3  0.561544  \n",
       "2  0.559054  \n",
       "0  0.556136  \n",
       "1  0.530958  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"Logistic Regression\", \n",
    "          \"K-Nearest Neighbors\",\n",
    "          \"Support Vector Machine\",\n",
    "          \"Random Forest\"]\n",
    "\n",
    "optimized_parameters = [log_grid.best_params_, \n",
    "                        knn_grid.best_params_,  \n",
    "                        svm_grid.best_params_,\n",
    "                        rf_grid.best_params_]\n",
    "\n",
    "F1 = [log_grid.best_score_,\n",
    "      knn_grid.best_score_,\n",
    "      svm_grid.best_score_,\n",
    "      rf_grid.best_score_]\n",
    "       \n",
    "model_df = pd.DataFrame({\"model\" : models, \n",
    "                         \"optimized_parameters\" : optimized_parameters, \n",
    "                         \"macro-F1\" : F1})\n",
    "\n",
    "with pd.option_context('display.max_colwidth', 150):\n",
    "    display(model_df.sort_values(by=\"macro-F1\",ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest model performed the best, although the macro-F1 score was quite similar across models. I ran the random forest model with the optimized parameters on the test set for a final assessment of macro-F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5634600022823233"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model to entire SMOTE training set\n",
    "model_best = RandomForestClassifier(max_depth=16,max_features=.1,min_samples_leaf=5,n_estimators=100,random_state=10)\n",
    "model_best.fit(X_train_smote,y_train_smote)\n",
    "\n",
    "#Predict test values\n",
    "y_pred = model_best.predict(X_test)\n",
    "\n",
    "#Calculate weighted-F1\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(y_test,y_pred,average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I built a confusion matrix. The model clearly had trouble correctly predicting \"Top 5\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Not Top 5'), Text(0, 1.5, 'Top 5')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3sAAALdCAYAAACV/3qkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd3QV1frG8eckJCGUQKiiiIRiIEAEQaqEXg0dxKCABSkhlCtKERBFmkqRItKbElAgQkJRQBFRUURQDEVCKAJKAIEUWiDn/P7gx7nEk0ByDJmTud/PWmctmdkz84733nV9ffbsbbHZbDYBAAAAAEzFzegCAAAAAABZj2YPAAAAAEyIZg8AAAAATIhmDwAAAABMiGYPAAAAAEyIZg8AAAAATIhmDwDug61bt6pfv35q2LChKleurLp166p///7atWtXttWwa9cutW3bVlWqVFHt2rX1119/ZfkzunfvroCAgCy/b0YMHz5c/v7+8vf31w8//JDuuL/++ksVKlSQv7+/Zs+e7fTzjh49mqFxP/74479+FgAAWSGX0QUAgJkkJiZq6NCh+uqrrxQYGKinn35aRYoU0enTp7VmzRp1795dI0eOVI8ePe5rHVarVYMHD9aVK1c0aNAg5cuXTw888ECWP6dv3766cOFClt83sz7//HPVrl07zXObNm3Sv91Sds6cOZo9e7b27dt3z7Fly5bVu+++q4oVK/6rZwIA8G/R7AFAFnr99df11VdfpdnQ9erVS88++6zGjx+v8uXLq06dOvetjnPnzunvv/9WixYt1KtXr/v2nHr16t23e2dUqVKltGXLFr3xxhtyc3OcsLJx40YVLlxYf//9t9PP+O6773Tz5s0MjS1SpIjatWvn9LMAAMgqTOMEgCyyfft2bd68WcHBwWkmd/nz59ebb74pSfroo4/uay03btywP9PsWrZsqfPnz2v37t0O506ePKnffvtNLVq0MKAyAACMRbMHAFkkMjJSktStW7d0xzz++ONav369Zs2aler4rl271KtXL9WoUUNVqlRRmzZttGTJEqWkpNjHnDp1Sv7+/lqyZIk++ugjtWrVSpUrV1ajRo00bdo0e4M3fPhwNWnSRJK0evVq+fv7a+bMmfbrR44c6VBXWt/erV27Vp06dVL16tVVrVo1de7cWatWrbrndRcuXNDbb7+tRo0aqXLlynryySc1YsQI/fnnnw7XtmvXTtHR0XrhhRdUrVo1Va9eXf3799exY8fS/Xv4Ty1atJCbm5u++OILh3ObNm1Snjx51LBhwzSv3bBhg3r06KGaNWuqUqVKqlu3rgYPHqwTJ07Yx/j7+2vXrl1KSUmRv7+/hg8fnqr+5cuXq1atWqpWrZoWLFjg8M3erFmz5O/vrzFjxqR69tKlS+Xv769x48Zl+F0BAMgMpnECQBbZt2+fcuXKpSpVqtx1XPny5VP9OTIyUkOHDtUDDzyg559/Xj4+Ptq2bZsmTpyon376STNnzkw1PXHZsmW6fv26QkJCVKRIEX322WeaM2eOcuXKpQEDBqhr166qUKGCJk6cqJo1a6pz587y9/fP1Lts2LBBw4YNU/369dWpUyfZbDZFRUVp1KhRSk5O1rPPPpvmdXFxcQoJCdGZM2fUqVMnBQQEKDY2Vp988om2bdumFStWyM/PL9X4nj17qlmzZho+fLh+//13rVixQr///rs2b96c5rTMfypSpIhq1KihzZs3a9SoUbJYLPZzGzduVOPGjZU7d26H6xYsWKD33ntPQUFBGjRokNzc3LR7925t2LBBhw4d0saNG+Xm5qZ3331Xc+bM0fHjxzVp0iSVKlXKfo8TJ05oxowZ6tOnj65evaq6desqMTEx1XP69eunb7/9Vp988omeeuop1axZU4cPH9aUKVNUsWJFDR069J7vCACAM2j2ACCLnDt3Tr6+vvL09MzwNYmJiRo7dqyKFi2qdevWqUCBApKkHj166PXXX9eaNWsUGRmp9u3b26+5cOGCvvjiCxUvXlyS1LZtWwUFBSkiIkIDBgxQtWrVVLRoUU2cOFGlSpWyfz926tSpDNe1bt065cmTR/PmzbM3XJ07d1aXLl0UExOT7nXTpk3T6dOnNW3aNLVu3dp+vEWLFurevbvefPNNLV261H784sWLGjFihJ5//nn7seTkZK1atUq7du1Kd9GVf2rZsqXGjh2rn3/+WTVq1JAkHTt2TAcPHlRYWJjD+JSUFM2fP1/VqlXTvHnz7A1iSEiIJGn9+vU6ePCgKlWqpHbt2mn16tU6ceKEw7d4V69e1ciRI9WlSxf7sR9//DHVGHd3d7333ntq27atRo0apYiICL366qtyd3fX1KlTM/XfFwAAMoNpnACQRdzd3TO8iMdt3333nRITE9WjRw97o3fboEGDJN1aafJONWvWtDd6kpQnTx6VLVtW586dc7JyRw888ICuXLmit956S/v375fNZpOXl5ciIyPt3x3+k9Vq1ZYtW1S2bNlUjZ4kPfHEE6pbt65+/PFHh9U727Ztm+rPlStXliSdP38+w/WmNZVz48aNyp8/v4KCghzGu7u7a8eOHakaPelW8307Bbxy5UqGnt2oUaN7jnn44Yc1cuRInThxQh07dtTvv/+u0aNHq0yZMhl6BgAAzqDZA4AsUqxYMSUkJCg5OTnD15w8eVKSVK5cOYdzxYsXl4+Pj0MiV7hwYYexnp6eslqtmaw4fWFhYapUqZJWrlypjh07qk6dOhoyZIi2bNmS7jYGFy9eVFJSUprvIt16R5vNptOnT9uPubm5qVChQg7vIinV94r3cudUztv1bdq0SU2bNk03OfP09NS+ffs0atQoPffcc2rYsKGeeOIJrVmzRpIy9PfTYrGk+Z9HWjp37qyGDRvqxIkTCgoKUseOHTP4dgAAOIdmDwCyyBNPPKGUlBT9+uuvdx3Xt29fjRo1StevX7/n/m8pKSkOzUpGvmPLrH8mksWKFVNERIQ++eQT9evXT6VLl9amTZsUFhamAQMGpHmPezVHt5u3O9/nzlTt32rVqpXOnDmjX375RTExMYqJiXFIGO/0+uuv66WXXtKvv/4qPz8/vfjii1q+fLn69euX4We6ubll+B3i4+N18OBBSdLevXsdFqwBACCr0ewBQBZp1aqVJGnFihXpjomOjta2bdu0f/9+eXl56eGHH5YkHTlyxGHsX3/9pcuXL6tEiRJZUl+uXLc+004refznlMnDhw9r3759qlq1qgYPHqyVK1fq22+/VbVq1bRlyxbFxsY63KNQoULKmzdvmu8i3XpHNze3+7K5uyQ1b95c7u7u2rx5szZu3KiCBQuqbt26aY7dvXu31qxZo/bt2ysyMlJvv/22evTooerVq+vixYv3pb4xY8bo7NmzGjlypK5du6Zhw4ZlaRoLAMA/0ewBQBapU6eOGjVqpA0bNqS5j9758+c1ZMgQSf/9Hu/JJ59U3rx59dFHHyk+Pj7V+BkzZkiSmjVrliX1+fr6ysPDQwcPHkzVZOzdu1d//PFHqrGvvPKKQkNDlZSUZD9WqFAhlS5dWtJ/G8c7ubu7q2nTpoqNjdXGjRtTndu1a5d++OEH1axZ0+HbxKxyeyrnli1btHnzZjVv3jzNOiXp0qVLkm5NLb0zmTt9+rT9G8k7p5G6ubn9q8Zs3bp12rRpk0JCQtSjRw/16dNHu3bt0uLFi52+JwAA98JqnACQhSZNmqS+fftq3LhxioqKUtOmTVWgQAEdOXJEERERunz5sl555RX7vm/58+fXG2+8oREjRqhdu3bq0qWLfeuF7777Tg0bNnRYwMRZXl5eatWqlSIjI9WvXz81adJEp06dUnh4uPz8/FI1fKGhofrPf/6jkJAQdejQQfny5dMvv/yitWvXqkmTJnrkkUfSfMaQIUO0a9cuvfrqq9q5c6cCAgJ09OhRrVy5UgULFtQbb7yRJe+SnpYtW+qtt96SJI0aNSrdcY8//rgKFiyo2bNn6/Lly3rooYd09OhRrVmzRtevX5ekVFsoFClSRDabTTNnzlSNGjVUp06dDNf0559/6u2339ZDDz2kV199VdKtqbybN2/W+++/r3r16qlChQrOvC4AAHdFswcAWahgwYJatmyZIiMjtXbtWn300Ue6ePGiChQooHr16qlnz56qXr16qmvat2+vBx54QPPmzdOiRYt08+ZN+fn5aeTIkXr22Wez9Bu9MWPGKF++fNq8ebO+//57lS9fXu+++6527typ5cuX28e1bt1anp6eWrx4sebNm6fLly+rZMmSGjBggHr16pXu/YsXL67Vq1frgw8+0FdffaXPPvtMhQsXVocOHRQaGnrfpnDe1qJFC40bN06+vr6qWbNmuuMKFSqkBQsWaMqUKVq+fLlSUlJUokQJde3aVU899ZTatWun7777Ti1atJAkvfzyyzp8+LDmzp2rvXv3ZrjZs1qtGjZsmBITEzVjxgzlzZtXkuTh4aEJEyaoa9eueu2117RmzRq2YAAAZDmL7V6rAwAAAAAAchy+2QMAAAAAE6LZAwAAAAATotkDAAAAABOi2QMAAAAAE6LZAwAAAAATMu3WCzfOHzW6BACApK7VBxtdAgDgDhEnIo0uIdOM/md7jyJlDH2+s0j2AAAAAMCEaPYAAAAAwIRMO40TAAAAgElYU4yuIEci2QMAAAAAEyLZAwAAAODabFajK8iRSPYAAAAAwIRo9gAAAADAhJjGCQAAAMC1WZnG6QySPQAAAAAwIZo9AAAAADAhpnECAAAAcGk2VuN0CskeAAAAAJgQyR4AAAAA18YCLU4h2QMAAAAAE6LZAwAAAAATYhonAAAAANfGAi1OIdkDAAAAABMi2QMAAADg2qwpRleQI5HsAQAAAIAJ0ewBAAAAgAkxjRMAAACAa2OBFqeQ7AEAAACACZHsAQAAAHBtVpI9Z5DsAQAAAIAJ0ewBAAAAgAkxjRMAAACAS7OxQItTSPYAAAAAwIRI9gAAAAC4NhZocQrJHgAAAACYEM0eAAAAAJgQ0zgBAAAAuDYWaHEKyR4AAAAAmBDNHgAAAACYENM4AQAAALg2a4rRFeRIJHsAAAAAYEIkewAAAABcGwu0OIVkDwAAAABMiGYPAAAAAEyIaZwAAAAAXJuVaZzOINkDAAAAABMi2QMAAADg2ligxSkkewAAAABgQjR7AAAAAGBCTOMEAAAA4NpYoMUpJHsAAAAAYEIkewAAAABcms2WYnQJORLJHgAAAACYEM0eAAAAAJgQ0zgBAAAAuDb22XMKyR4AAAAAmBDJHgAAAADXxtYLTiHZAwAAAAATotkDAAAAABNiGicAAAAA18YCLU4h2QMAAAAAEyLZAwAAAODarClGV5AjkewBAAAAgAnR7AEAAACACTGNEwAAAIBrY4EWp5DsAQAAAIAJ0ewBAAAAgAkxjRMAAACAa7MyjdMZJHsAAAAAYEIkewAAAABcGwu0OIVkDwAAAABMiGYPAAAAAEyIaZwAAAAAXBsLtDiFZA8AAAAATIhkDwAAAIBrI9lzCskeAAAAAJgQzR4AAAAAmBDTOAEAAAC4NJstxegSciSSPQAAAAAwIZI9AAAAAK6NBVqcQrIHAAAAACZEswcAAAAAJsQ0TgAAAACuzcY0TmeQ7AEAAACACZHsAQAAAHBtLNDiFJI9AAAAADAhmj0AAAAAyEJr165Vu3bt9NhjjykoKEjjx49XYmKiw5g2bdooMDBQDRs21Pvvv6/k5ORUY5KTkzVt2jQ1atRIVapUUZs2bbRu3boM10GzBwAAAMC12azG/jLh448/1rBhw1S1alXNnDlTffv2VWRkpF5++WXZbDZJ0qeffmofM2PGDHXo0EHz5s3TW2+9lepeI0aM0KJFixQSEqIZM2aofPnyGjp0aIYbPr7ZAwAAAIAscPPmTX3wwQdq3LhxqsbNw8NDo0aN0u7duxUYGKipU6eqRYsWevvttyVJDRs2VN68eTV58mS9+OKLKlu2rKKjo7V+/XqNHj1azz33nCSpUaNGunz5siZPnqw2bdrIze3u2R3JHgAAAADXZrUa+8sgNzc3LVmyRK+//nqq415eXpKk69eva9++fbp48aJat26dakybNm1ks9n05ZdfSpK+/vprSXIYFxwcrLNnz+q33367Zz0kewAAAABwFwkJCUpISHA47uPjIx8fH/uf3dzc5O/vb/9zUlKSdu/ercmTJ6tChQqqVauWVq9eLUkqW7ZsqnsVL15cefLk0ZEjRyRJsbGx8vX1VaFChVKN8/PzkyTFxMToscceu2vdNHsAAAAAcBdLly7VrFmzHI6HhYVpwIABaV5z8uRJNW3aVJJUsGBBvfnmm/Lw8LAv1JI/f36Ha/Lly2c/n5CQkO4Y6VYjeS80ewAAAABcWyYXSclqPXv2VIcOHRyO35nq/VP+/Pm1ZMkSXblyRUuXLlX37t31/vvvy/r/00ItFkua193+Ds9ms6U75m7X34lmDwAAAADu4p/TNTOiYMGCqlOnjiSpfv36Cg4O1owZM/TMM89IkhITE1W8ePFU1yQlJdnTPB8fH4ftGm6PkdJOBv+JBVoAAAAAIAvEx8crMjJSx44dS3Xc09NT/v7++uuvv+zf6h0/fjzVmLi4OF25ckXlypWTdOubvgsXLig+Pj7VuNv3vj3ubmj2AAAAALi2HLIap81m07Bhwxy+74uPj9eePXtUsWJFVatWTQUKFND69etTjYmKipLFYlFQUJAkqUGDBpKkDRs2OIwrWrSoAgIC7lkP0zgBAAAAIAsULFhQL730kubPn6/8+fOrSZMm+vvvv7Vw4UJduXJFw4YNk6enp/r3768JEyYod+7catmypfbt26c5c+aoY8eOevTRRyVJgYGBatasmSZMmKBLly6pYsWKioqK0vbt2/XOO+8oV657t3IW2+1t3E3mxvmjRpcAAJDUtfpgo0sAANwh4kSk0SVk2tUN7xv6fO+nMv7/ZVarVatXr1Z4eLiOHz8uLy8v1apVS4MGDUq13UJ4eLiWLVumU6dOqVixYmrfvr1CQ0NTNXHXrl3T1KlTtXHjRiUkJKh06dLq3bu3goODM1QLzR4A4L6i2QMA10Kzl3mZafZcCd/sAQAAAIAJ8c0eAAAAANdm8D57ORXJHgAAAACYEMkeAAAAANeWie0P8F8kewAAAABgQjR7AAAAAGBCTOMEAAAA4NpYoMUpJHsAAAAAYEIkewAAAABcGwu0OIVkDwAAAABMiGYPAAAAAEyIaZwAAAAAXBsLtDiFZA8AAAAATIhkDwAAAIBrY4EWp5DsAQAAAIAJ0ewBAAAAgAkxjRMAAACAa2Map1NI9gAAAADAhGj2AAAAAMCEmMYJAAAAwLXZbEZXkCOR7AEAAACACZHsAQAAAHBtLNDiFJI9AAAAADAhmj0AAAAAMCGmcQIAAABwbUzjdArJHgAAAACYEMkeAAAAANdmI9lzBskeAAAAAJgQzR4AAAAAmBDTOAEAAAC4NhZocQrJHgAAAACYEMkeAAAAANdmsxldQY5EsgcAAAAAJkSzBwAAAAAmxDROAAAAAK6NBVqcQrIHAAAAACZEsgcAAADAtZHsOYVkDwAAAABMiGYPAAAAAEyIaZwAAAAAXJuNaZzOINkDAAAAABMi2QMAAADg0mxWm9El5EgkewAAAABgQjR7AAAAAGBCTOMEAAAA4NrYZ88pJHsAAAAAYEI0ewAAAABgQkzjBAAAAODa2GfPKSR7AAAAAGBCJHsAAAAAXBv77DmFZA8AAAAATIhmDwAAAABMiGmcAAAAAFwb++w5hWQPAAAAAEyIZA8AAACAayPZcwrJHgAAAACYEM0eAAAAAJgQ0zgBAAAAuDYb++w5g2QPAAAAAEyIZA8AAACAa2OBFqfQ7AHZ5PgfpzR97hLt/e2Arly5psoVH1Xvnl1Vu0a1VOM2bv1aS1dE6NiJU8qTJ7caPVlbYS/3UGHfgg73/GrHTi0OX61Dh2PlnTu3qlYJ0OB+L6jMIw9n12sBQI73aDV/jV8zSaOffl2Hdh9Mde6JZrXUrnd7+VUqIzd3N52KOan1CyO1/bOvU43zzO2pzgOeVr3g+iryYBFdu3xV0T9EK3zyxzp95FQ2vg0A/BfTOIFs8MepP9Wt93/08y/RCunURoP69FRiUpJeHjxSm7ftsI9bHL5aQ8e8ozze3nol9EV1DG6hjVu+VkivQboUn5Dqnisj1mvg8LG6eTNFQ/r3UteOwfpp7z517ztEp/+Ky+5XBIAcqXipB/TanOFyd3d3OFcv+EmNWDBSeX3y6tPpK7X8nY9kTbFq0PuvqMvArqnGvjZnuDqHPa2YX37Xwjfn64vlnyuwbqDeWTtZJcvzL+AAGINkD8gGU2cv0pWr17R68SyVK/OIJKlDcAu16fayJs9aoOaN6is+IVHT5y5VtcAALZwxUW5ut/5dTJWK/how/C19vGqdwnp1lyT9FXdOk2ctUPXHKmvB9Any8PCQJNWrVV3P9XlFi5av0uhXw4x5WQDIIao3rqEBUwbLp5CPwzn3XO7qPb6fTsee0mttXtHN5JuSpI1L1mtCxDvqPOBpbVnxhS6du6TareqoeqMa+mTaCn3y/gr7PXZu/F7vrJus7sN6aGKv8dn2XoApWVmgxRkke0A2cHd3V7OG9eyNniTl8c6twAB//XnmrOITEvXH6T9VJeBRhXRqY2/0JKlW9cckSYcOx9qPRX6+VdeuX9erYb3sjZ4kVa1cUQN691BgpQrZ8FYAkHMNnjFEIxe/oUvnL+mbddsdzpcNLKf8BfNr+2df2xs9SbJarfo2coc8PD30aDV/SVLV+rem429duTnVPY7tP6qTh/9QQM1K9/FNACB9JHtANpjy9giHYzdvpigm9rh88udTvrx5VKWivz76cIrDuAOHj0iSHnygmP3YT3v2qWABH1Wu+Kgk6cbNm0pJSVFuLy/16Rlyn94CAMzj4XIPa/l7H2ndvM/UKbSLw/mj0bEa0LifkuIvO5zzKXwrCUy5mSJJ+vjdj7Q5/Av9feZvx7GFfJSSwsISwL9m439Hzsj2Zi8uLk6FCxdWrlz/ffTly5e1cuVKHThwQIUKFVK9evXUsGHD7C4NyBbxCYmKPf6H5i/7RMdPntbr/+nn8K2IzWbTX3FntefX/Zo6e5F8C/qoxzMd7eePHj+pBx8opoOHY/XezPn6+ddoWa1WVQnw17BBfVS1csXsfi0AyFGGtXtVN2/cTPf8zeSbOh172uF47rzeavJ0MyVfS9bvPx+SJCVdSlTSpUSHsXWfqqfCJYro+w3fZV3hAJAJ2d7sNWzYUMuXL9fjjz8uSfr777/VrVs3nThxQrlz59bNmzf18ccfq2HDhpo+fbo8PT2zu0Tgvgp9bYx+jb612lvjoDpq37qZw5gTJ08rOORlSZK7u5vGDh+skg8+YD+fkJgki5tFz/cfquaNnlS3Tm105uw5zVu2Ui8OGKalH7ynKgH+2fNCAJAD3a3RS4+bm5sGTR0s32K++mxOhJLik9IdW8LvQfUe1083km9o9cxP/k2pAOC0bP9mz2ZL/XHlu+++q4sXL2r+/Pnau3ev9u7dq3Hjxum7777TvHnzsrs84L7r+UwHTZ84Wt2fbq9vvtulkJcHKz4h9b8RzuPtrSlvv64Jo19VtSoBGjl+qt6fs8R+/sbNG4o7e15dOzylcSNfUbNGT6p71w5aMH2SUlJSNOWDBdn8VgBgbu653DV4+iuq1bKODv50QCsmf5zu2IfKldTYFePkU8hHi99eqOMHj2dfoYBZWW3G/nIowxdo2bZtm0JDQ1W/fn1ZLBZ5eHioU6dOeumll7Ru3TqjywOyXPNG9dUkqK6GDeqj4f/pq9jjf2j56shUY4oVLawWjeurbcsmWjhjkh6rXFGLlq/SydN/SZJye3lJkrp1bpvqOv9yfqpaOUB79h3QtevXs+eFAMDk8uTPo1FLx+jJtkE69PNBjXv+rXSTwYpPBGjC6kkqXKKIlk5YrM+XbczmagHgvwxv9q5fv67KlSs7HK9evbri4tgrDOYW3LyRJGn/ocPpjnF3d1erpg1ktVrtK3KWKH5rsZaihQs5jC9SuJCsVquuXr12HyoGgP8tvsUKadynE/XYk1W15+uf9dazb+hq0tU0x9ZpXVdjPh6rPPnz6sPhH2jd3M+yuVrAvGxWq6G/nMqQZu/6HYlDQECATp065TDm8OHDKl68eHaWBdwXcefOq3XXlzRm0nSHc5ev3PoHhtxeXlr52Xo1bNtNu/bsS2PcFUmSl9etb1grB9xahfPIsRMOY0+e/kt583irYAHHfaMAABlXoEhBvf3pBJUO8NOXn27VhBff1vWrac+aqNO6nl6Z9ZqsVqve6T1BW1Z8kc3VAoAjQ5q9F198UU2bNtWgQYPk7e2tadOm2VO869evKzIyUh9++CErcsIUihUpLKvVqk1bt9unYd42f9mtj/abBNVVmUdK6fzfF7U4fHWqMfEJifp07UYV8MmvGlWrSJLatWoqSZq7JDzVd7A/7N6rA7/HqHnjW9OiAQDOsVgsenX2MD3o96DWL4zUB6/NkDWdLRRKPVpKA6cN1o3rNzS2+xjt/vKnbK4WANKW7atxrlixQgcOHFB0dLQOHDig2NhY3bx5UzExMSpevLhWrVqlcePGKSAgQGFhYdldHpDlLBaLRg3pr7Chb6pHv1f1TKdg5c+bV9u/36XvfvxZLRrXV6umDWSxWBTcorHWf/GVeg16XU0b1P3/Rm+D/r5wSZPfHqE8ebwlSU9UC1RIxzZaERGllwaOUIvG9fXnmTgtXxWp4kULa1Cf5419aQDI4Wq3qqtKtSop4UKCju4/qqAODR3GHNp9UGdPxqn7iJ7yyu2ln7b8qGIPF1exh1PPTLJZrdqx7ptsqhwwqRy8SIqRLLZ/Lo+ZzZKTk3Xo0CH5+fkpf/78io6O1pEjR9SqVSt5/f8iFM64cf5oFlYJ/Hu/Rh/Uh4vDtXffft24eVOlS5VUp+AWCunURm5ut0J2q9Wq5avWaXXk5zpx6k/l8c6taoEB6vt8N4etFGw2m9ZEfa6VEet19MRJ5cubV/Vr19Dgvi+oaBHHb/kAo3StPtjoEoC76jo4RF3/E3A7IggAACAASURBVKLXOw3Tod23tsbpM76fWjzX6q7XvT94qr757GutOLRKXt7p/zNLys0UdSnbIUtrBv6NiBOR9x7kYi6P72Ho8/OOXGbo851leLN3v9DsAYBroNkDANdCs5d5ObXZy/ZpnAAAAACQKbacuyKmkQzfegEAAAAAkPVI9gAAAAC4NhZocQrJHgAAAACYkEs1e8nJyUaXAAAAAACmYPg0zujoaM2cOVO7du3StWvXlDdvXgUFBWnQoEF65JFHjC4PAAAAgNGsLNDiDEObvT179qhnz57y9vZW48aNVbhwYZ07d047duzQN998o08//VRlypQxskQAAAAAyJEMbfamTZumsmXLaunSpSpQoID9+MWLF9WzZ09NnTpVs2bNMrBCAAAAAIZjgRanGPrNXnR0tPr165eq0ZMkX19f9enTRz/++KNBlQEAAABAzmZos5c3b950F2Vxd3dXrlyGf1IIAAAAADmSoc1eSEiIZs6cqbi4uFTHk5KSNH/+fD377LMGVQYAAADAZdisxv5yKEOjs6SkJMXHx6tly5aqX7++SpQooQsXLujbb79VQkKCihcvrrCwMEmSxWLRzJkzjSwXAAAAAHIMQ5u9qKgoeXh4yMPDQ3v27LEfd3d3l6+vr/bt22dgdQAAAABcAgu0OMXQZu/bb7818vEAAAAAYFousQLKjRs3dODAASUkJKhQoULy9/dncRYAAAAA+BcM76jWrl2rSZMmKT4+3n7Mx8dHw4YNU8eOHQ2sDAAAAIArsFlz7iIpRjK02duxY4dGjBihgIAADRw4UMWKFdOZM2cUERGhkSNHqlixYnryySeNLBEAAAAAciRDm725c+eqdu3aWrRokSwWi/34s88+qxdeeEHz58+n2QMAAAD+17FAi1MM3Wdv//79CgkJSdXoSbe2WQgJCdH+/fsNqgwAAAAAcjZDm73cuXPLZku/S09JScnGagAAAADAPAxt9gICArRy5co0z4WHh6tSpUrZXBEAAAAAl2O1GfvLoQz9Zi80NFTPPfecOnbsqLZt26pYsWI6e/asIiMjdejQIc2ZM8fI8gAAAAAgxzK02atevbomT56sCRMmaNKkSfbjhQsX1qRJkxQUFGRgdQAAAACQcxm+z95TTz2lVq1a6fDhw7p48aJ8fX1Vvnx5ubu7G10aAAAAAFdgY589Z2T7N3s9evRQTExM6iLc3FShQgXVqVNHFSpUoNEDAAAAgH8p25O9Xbt2KTExMbsfCwAAACCnysGLpBjJ0NU4AQAAAAD3B80eAAAAAJiQIQu0rF+/Xj///PM9x1ksFvXq1SsbKgIAAADgqmxM43SKIc1eeHh4hsbR7AEAAACAcwxp9mbMmKFKlSoZ8WgAAAAAOQ3JnlMMafaKFCmihx56yIhHAwAAAMB9tXnzZi1atEhHjhyRp6enAgICNGjQIFWpUkWSdOnSJdWqVSvNaxcvXqy6detKkpKTk/XBBx8oMjJS58+fV+nSpdWrVy+1a9cuQ3UYvqk6AAAAAJhFRESERowYoeDgYPXu3VvXrl3TokWLFBISoiVLlqhGjRo6cOCAJGncuHHy8/NLdb2/v7/9r0eMGKHNmzdrwIABKl++vKKiojR06FBJylDDR7MHAAAAwLVZrUZXkGHTp09XnTp1NGXKFPuxoKAgNWnSRPPnz1eNGjUUHR0td3d3BQcHy9vbO837REdHa/369Ro9erSee+45SVKjRo10+fJlTZ48WW3atJGb2903V8j2rReWLVumRx99NLsfCwAAAAD31eXLl9W4cWN169Yt1fF8+fKpRIkSOnPmjCTpwIEDKlOmTLqNniR9/fXXkqTWrVunOh4cHKyzZ8/qt99+u2c92d7s1axZU/ny5cvuxwIAAADIqaw2Y38ZlDdvXo0ZM0bNmzdPdfzYsWOKiYlRxYoVJUn79++Xh4eHevXqpccff1xVq1ZV3759FRsba78mNjZWvr6+KlSoUKp73Z72GRMTc896mMYJAAAAAHeRkJCghIQEh+M+Pj7y8fG567VJSUkaMmSIPDw81Lt3byUmJurkyZPy9vZWhw4d1LdvXx07dkyzZ8/WM888ozVr1qhUqVJKSEhQ/vz5He53OzhLSkq6Z900ewAAAABwF0uXLtWsWbMcjoeFhWnAgAHpXhcXF6e+ffsqJiZG06dPV5kyZXT9+nUtXrxYRYsWVbly5SRJNWrUUI0aNdSmTRt9+OGHmjhxomw2mywWS7r3vtu522j2AAAAALg2g/fZ69mzpzp06OBw/G6p3p49ezRw4EBduXJFs2fPVlBQkCTJy8tLderUcRjv5+enMmXK6ODBg/Z7JyYmOoy7neillfr9U7Z/s3enP//8Uzdu3Ejz3LVr17R3795srggAAAAAUvPx8VHJkiUdfuk1e+vXr1fPnj3l4eGh8PBwe6MnScePH9fy5cvti7Xc6dq1a/Zv9MqWLasLFy4oPj4+1Zhjx45Jkj0VvBtDm70mTZooOjo6zXN79+7Viy++mM0VAQAAAHA1NpvN0F9mfPHFF3rttddUoUIFrV69WhUqVEh1Pj4+XmPHjtWKFStSHf/555/1xx9/2FO/Bg0aSJI2bNiQalxUVJSKFi2qgICAe9aS7dM4J0+ebI8ebTabFi5cqCJFijiM27dvn3Lnzp3d5QEAAACAUy5duqSRI0fK29tboaGhOnbsmD2JkyRvb28FBgaqadOmWrBggSTpiSee0JEjRzR79myVK1dOPXr0kCQFBgaqWbNmmjBhgi5duqSKFSsqKipK27dv1zvvvKNcue7dymV7s+fj42N/MYvFoq1btzqMcXNzk4+Pj8LCwrK7PAAAAABwyo4dO+zf2fXt29fhvJ+fnz7//HNNmTJFCxcuVFRUlBYtWqQCBQroqaee0sCBA+Xl5WUfP3nyZE2dOlXh4eFKSEhQ6dKlNWXKFAUHB2eoHosts7lkFqpQoYLCw8P1+OOPZ/m9b5w/muX3BABkXtfqg40uAQBwh4gTkUaXkGkJLze/96D7yGf+ZkOf7yxDV+P88ssvVaxYMSNLAAAAAABTMrTZe+ihhxQXF6eZM2fq+++/V2Jionx9fVW7dm3169dPJUqUMLI8AAAAAK7A4K0XcipDm70zZ86oc+fOunTpkqpWraqiRYsqLi5Oa9as0ZdffqmIiAgVL17cyBIBAAAAIEcytNmbNm2aJGnt2rWp9ok4cuSIXnjhBc2YMUPjx483qjwAAAAAyLEM3Wdvx44d6t+/v8OGgOXKlVO/fv30zTffGFQZAAAAAFdhs9oM/eVUhjZ7V69eVcmSJdM8V7JkSV26dCmbKwIAAAAAczC02XvkkUe0c+fONM/t3LlTDz74YDZXBAAAAADmYOg3e126dNHEiRNVsGBBdejQQUWLFtW5c+f02Wef6aOPPlJoaKiR5QEAAABwBTl4KqWRDG32nnnmGe3cuVNTp07VtGnTZLFYZLPZZLPZ1KhRI/Xu3dvI8gAAAAAgxzK02XN3d9esWbP0/fffa+fOnbp06ZIKFiyoOnXqqG7dukaWBgAAAMBVWI0uIGcytNm7rW7dujR3AAAAAJCFsr3Z++mnnzI1/oknnrhPlQAAAACAeWV7s9e9e3dZLJYMjbVYLDpw4MB9rggAAACAK8vJe90ZKdubvalTp971/Pnz5zVr1iwlJCSoSpUq2VQVAAAAAJhLtjd7rVu3Tvfcl19+qblz5+rKlSsKCwtTv379srEyAAAAAC6JZM8pLrFAy9WrVzV+/HitWbNGpUqV0ocffqjAwECjywIAAACAHMvwZu+XX37R0KFD9ccff+iZZ57R8OHDlTt3bqPLAgAAAIAczbBmLyUlRTNnztSCBQtUsGBBzZ07Vw0aNDCqHAAAAACuin32nGJIs3fs2DG9+uqr2r9/v5o1a6axY8fK19fXiFIAAAAAwJSyvdlbvny5Jk+eLHd3d02cOFEdOnTI7hIAAAAA5CBsveAci81my9a/cxUqVJAkubu7K1euu/eaFotFv/zyi1PPuXH+qFPXAQCyVtfqg40uAQBwh4gTkUaXkGkXuzQ09Pm+q7429PnOyvZkr3379hneVB0AAAAA4Jxsb/YmTZqU3Y8EAAAAkJOxQItT3IwuAAAAAACQ9QzfZw8AAAAA7oYFWpxDsgcAAAAAJkSzBwAAAAAmxDROAAAAAK6NBVqcQrIHAAAAACZEsgcAAADApdlI9pxCsgcAAAAAJkSzBwAAAAAmxDROAAAAAK6NaZxOIdkDAAAAABOi2QMAAAAAE2IaJwAAAACXxmqcziHZAwAAAAATItkDAAAA4NpI9pxCsgcAAAAAJkSzBwAAAAAmxDROAAAAAC6NBVqcQ7IHAAAAACZEsgcAAADApZHsOYdkDwAAAABMiGYPAAAAAEyIaZwAAAAAXBrTOJ1DsgcAAAAAJkSyBwAAAMC12SxGV5AjkewBAAAAgAnR7AEAAACACTGNEwAAAIBLY4EW55DsAQAAAIAJkewBAAAAcGk2Kwu0OINkDwAAAABMiGYPAAAAAEyIaZwAAAAAXBoLtDiHZA8AAAAATIhmDwAAAABMiGmcAAAAAFyazcZqnM4g2QMAAAAAEyLZAwAAAODSWKDFOSR7AAAAAGBCNHsAAAAAYEJM4wQAAADg0mxWFmhxBskeAAAAAJgQyR4AAAAAl2azGV1BzkSyBwAAAAAmRLMHAAAAACbENE4AAAAALo0FWpxDsgcAAAAAJkSyBwAAAMClkew5h2QPAAAAAEyIZg8AAAAATIhpnAAAAABcGvvsOYdkDwAAAABMiGQPAAAAgEtjgRbnkOwBAAAAgAnR7AEAAACACTGNEwAAAIBLs9mYxukMkj0AAAAAMCGSPQAAAAAuzWY1uoKciWQPAAAAAEyIZg8AAAAATIhpnAAAAABcmpUFWpxCsgcAAAAAJkSzBwAAAAAmxDROAAAAAC6NffacQ7IHAAAAACZEsgcAAADApdmsJHvOINkDAAAAABOi2QMAAAAAE2IaJwAAAACXZrMZXUHORLIHAAAAACZEsgcAAADApbFAi3NI9gAAAADAhGj2AAAAAMCEMj2NMzk5WcuWLdOWLVv0559/atq0afLy8lJERIRCQ0NVtGjR+1EnAAAAgP9RVhvTOJ2RqWbv6tWr6tmzp/bt2ydvb29du3ZNN27c0NmzZ7VixQrt2LFD4eHhKlas2P2qFwAAAACQAZmaxvnhhx8qOjpa7733nrZu3Srb/6+B2rp1a02YMEFnzpzR3Llz70uhAAAAAP432WwWQ385VaaavU2bNqlDhw5q06aN3NxSX9qxY0d16dJF27dvz9ICAQAAAACZl6lm78yZMwoMDEz3fEBAgM6ePfuviwIAAAAA/DuZ+mavQIECiouLS/d8bGysfHx8/nVRAAAAAHDb/389hkzKVLJXv359rVy5Ms2G77ffftPKlStVr169LCsOAAAAAOCcTCV7AwcO1LZt29S2bVvVqlVLFotFq1evVnh4uLZt2yZvb2/179//ftUKAAAA4H8QWy84J1PJXokSJfTJJ5+ocuXK2rJli2w2mzZs2KAtW7YoMDBQH3/8sUqVKnW/agUAAAAAZFCmN1V/5JFHtHDhQsXHx+vEiROy2WwqWbKkChcufD/qAwAAAAA4IdPN3m0FChS468qcAAAAAJAVcvJed0bKVLM3evToe46xWCwaO3as0wUBAAAAQE62efNmLVq0SEeOHJGnp6cCAgI0aNAgValSxT5m7dq1WrhwoU6cOKFChQqpffv2Cg0Nlaenp31McnKyPvjgA0VGRur8+fMqXbq0evXqpXbt2mWojkw1e6tWrUr3nMVikaenp7y8vGj2AAAAAGSZnLT1QkREhEaMGKHg4GD17t1b165d06JFixQSEqIlS5aoRo0a+vTTTzV69Gg9/fTTGjJkiH799VfNnTtX586d0/jx4+33GjFihDZv3qwBAwaofPnyioqK0tChQyUpQw2fxWbL+N+606dPOxxLSUnRuXPntG7dOn3//fdavny5ihcvntFb3jc3zh81ugQAgKSu1QcbXQIA4A4RJyKNLiHT9jycsSTrfnn85LoMj23QoIH8/Py0ZMkS+7GkpCQ1adJEVatW1YwZM9SgQQPVrFlTM2bMsI9ZsGCBJk+erA0bNqhs2bKKjo5Wp06dNHr0aD333HP2cX369NGBAwe0fft2ubndfb3NTK3G+dBDDzn8SpUqperVq2vs2LGqUKGC3nvvvczcEgAAAABM4fLly2rcuLG6deuW6ni+fPlUokQJnTlzRvv27dPFixfVunXrVGPatGkjm82mL7/8UpL09ddfS5LDuODgYJ09e1a//fbbPevJVLN3L0FBQdqxY0dW3hIAAADA/zirzWLoL6Py5s2rMWPGqHnz5qmOHzt2TDExMapYsaKOHDkiSSpbtmyqMcWLF1eePHns52NjY+Xr66tChQqlGufn5ydJiomJuWc9Tq/GmZbTp08rOTk5K28JAAAAAIZKSEhQQkKCw3EfHx/5+Pjc9dqkpCQNGTJEHh4e6t27t7Zu3SpJyp8/v8PYfPnyKTEx0f7M9Mbcvu+9ZKrZ27NnT5rHk5OTtX//fi1dulRVq1bNzC3vm2qVut17EADgvjt08aTRJQAA8K8sXbpUs2bNcjgeFhamAQMGpHtdXFyc+vbtq5iYGE2fPl1lypSR1WqVdGuBy7Tc/g7PZrOlO+Zu198pU81et27d0r2pzWZTnjx59Morr2TmlgAAAABwV0bvs9ezZ0916NDB4fjdUr09e/Zo4MCBunLlimbPnq2goKBU1yQmJjosbJmUlGRP83x8fOwp3z/HSGkng/+UqWYvLCwszePu7u4qVqyYmjdvnqGHAgAAAEBOkZHpmndav369RowYoSJFiig8PFwVKlSwn7v9rd7x48dVrlw5+/G4uDhduXLFfqxs2bLatGmT4uPjVaBAAfu4Y8eOSVKqa9OTqWavdu3aCgwMTLXRHwAAAADcT5lZJMVoX3zxhV577TVVrlxZc+bMUeHChVOdr1atmgoUKKD169eradOm9uNRUVGyWCz2BLBBgwaaNWuWNmzYkGp1z6ioKBUtWlQBAQH3rCVTzd6AAQPUvn17DRs2LDOXAQAAAIDpXbp0SSNHjpS3t7dCQ0N17NgxexInSd7e3qpUqZL69++vCRMmKHfu3GrZsqX27dunOXPmqGPHjnr00UclSYGBgWrWrJkmTJigS5cuqWLFioqKitL27dv1zjvvKFeue7dymWr2rl69al/qEwAAAADwXzt27LB/Z9e3b1+H835+fvr888/Vs2dPeXh4aNmyZVq/fr2KFSumvn37KjQ0NNX4yZMna+rUqQoPD1dCQoJKly6tKVOmKDg4OEP1WGw2my2jxY8ePVq//PKLZs+erYcffjijlxmicvHaRpcAABCrcQKAq7mZfNroEjLthwc7Gvr82n9GGPp8Z2Uq2fP09NTp06fVsmVLlS5dWkWKFJG7u3uqMRaLRQsXLszSIgEAAAAAmZOpZm/58uX2v46NjVVsbKzDmIzs9wAAAAAAGZWTFmhxJXdt9tauXasaNWqoZMmSkqRDhw5lS1EAAAAAgH/H7W4nR4wYob1792ZXLQAAAACALHLXZC8Ta7cAAAAAwH1hYxqnU+6a7AEAAAAAcqZ7LtDCgisAAAAAjGQ1uoAc6p7N3oQJEzRt2rQM39BisWjr1q3/qigAAAAAwL9zz2bvwoUL2VEHAAAAACAL3bPZe++999SmTZvsqAUAAAAAHNjEp2XOYIEWAAAAADCheyZ7AAAAAGAkKzvCOYVkDwAAAABM6K7NXlhYmPz9/bOrFgAAAABAFrnrNM6wsLDsqgMAAAAA0mRlgRanMI0TAAAAAEyIBVoAAAAAuDS2XnAOyR4AAAAAmBDNHgAAAACYENM4AQAAALg0q9EF5FAkewAAAABgQjR7AAAAAGBCTOMEAAAA4NJYjdM5JHsAAAAAYEIkewAAAABcGgu0OIdkDwAAAABMiGYPAAAAAEyIaZwAAAAAXBrTOJ1DsgcAAAAAJkSyBwAAAMClsfWCc0j2AAAAAMCEaPYAAAAAwISYxgkAAADApVmZxekUkj0AAAAAMCGSPQAAAAAuzcoCLU4h2QMAAAAAE6LZAwAAAAATYhonAAAAAJdmM7qAHIpkDwAAAABMiGQPAAAAgEuzGl1ADkWyBwAAAAAmRLMHAAAAACbENE4AAAAALs1qYZ89Z5DsAQAAAIAJ0ewBAAAAgAkxjRMAAACAS2OfPeeQ7AEAAACACZHsAQAAAHBp7LPnHJI9AAAAADAhmj0AAAAAMCGmcQIAAABwaVa22XMKyR4AAAAAmBDJHgAAAACXZhXRnjNI9gAAAADAhGj2AAAAAMCEmMYJAAAAwKXZjC4ghyLZAwAAAAATItkDAAAA4NLYesE5JHsAAAAAYEI0ewAAAABgQkzjBAAAAODSrEYXkEOR7AEAAACACZHsAQAAAHBpbL3gHJI9AAAAADAhmj0AAAAAMCGmcQIAAABwaeyz5xySPQAAAAAwIZI9AAAAAC6NrRecQ7IHAAAAACZEswcAAAAAJsQ0TgAAAAAujWmcziHZAwAAAAATotkDAAAAABNiGicAAAAAl2Zjnz2nkOwBAAAAgAmR7AEAAABwaSzQ4hySPQAAAAAwIZo9AAAAADAhpnECAAAAcGlM43QOyR4AAAAAmBDJHgAAAACXZjO6gByKZA8AAAAATIhmDwAAAABMiGmcAAAAAFya1WJ0BTkTyR4AAAAAmBDJHgAAAACXxtYLziHZAwAAAAATotkDAAAAABNiGicAAAAAl8Y0TueQ7AEAAACACZHsAQAAAHBpNqMLyKFI9gAAAADAhGj2AAAAAMCEmMYJAAAAwKVZLUZXkDOR7AEAAACACZHsAQAAAHBpbL3gHJI9AAAAADAhmj0AAAAAMCGmcQIAAABwaeyz5xySPfxfe3ceH9P59nH8O4klCSJEULS0RGxVWlsaIar8SovaKnZq3+nP2pYuqaWlihDUFolo0djp05VY22opGmkttTVtlQSJ2hIzzx8e83SaRU3JmRyft1deL3Of+5z7mvwxXHNd5z4AAAAATIhkDwAAAABMiDZOAAAAAC7NSiOnU6jsAQAAAIAJUdkDAAAA4NJ4zp5zqOwBAAAAgAmR7AEAAACACdHGCQAAAMClsT2Lc6jsAQAAAMA9kp6ertDQUE2YMMFh3GazqVatWgoICMjws2rVKod5ixcvVtOmTfXoo4+qadOmioyMlM12+xSYyh4AAAAAl5ZbN2i5fPmyRo0apX379qlixYoOx06dOqXU1FQNGzZMderUcThWrlw5+99nzJih999/X7169VKtWrW0fft2TZ48WZcvX9bAgQOzXZ9kDwAAAADusri4OE2ePFnnz5/P9Hh8fLwk6ZlnntEjjzyS6ZwzZ85o0aJF6tGjh0aOHClJCgkJkdVq1bx589SlSxd5e3tnGQNtnAAAAABwF6WkpKhfv34KCAjQ+vXrM50THx+vAgUK6OGHH87yOrt371ZaWpqaN2/uMN6iRQtdu3ZNO3bsyDYOKnsAAAAAXJrVYnQEd8bDw0ObNm1S+fLls5wTHx8vHx8fDR8+XLt379bly5dVs2ZN/fe//1WNGjUkSUePHpWkDNe5lSAeOXIk2zhI9gAAAAAgGykpKUpJSckw7u3tnWkbZb58+bJN9CQpISFBly5dUps2bdS1a1f9/vvvmj9/vrp06aLo6GjVrFlTKSkpcnd3l5eXl8O5BQsWlCSlpqZmuwbJHgAAAACXZjX44QtLly7V7NmzM4wPHjxYQ4YMuePrWa1WhYeHy9PTU48++qh9/Mknn1SzZs303nvvKSoqSjabTRZLxrLmrTE3t+zvyiPZAwAAAIBsdO/eXa1bt84wnt3mKNlxc3PLsAOnJBUtWlSPP/64vv32W/v109PTdeXKFXl6etrn3aroFSpUKNt1SPYAAAAAIBtZtWs6648//tAXX3yhWrVqyd/f3+HY1atXVbRoUUn/f6/eiRMnVLlyZfuc48ePS5IqVKiQ7TrsxgkAAADApdkM/rnbLBaL3njjDc2bN89h/PTp09q7d68CAwMlScHBwXJ3d9fGjRsd5m3YsEEeHh6qW7dututQ2QMAAACAHOTn56euXbsqKipKhQoV0lNPPaXffvtNERERKlSokP0+QD8/P3Xp0kWLFi3SjRs3VK9ePW3fvl3Lly/X0KFD7RXArJDsAQAAAHBpVqMDuAfGjh2rsmXLasWKFVq7dq08PDwUHBysESNGyNfX1z5vzJgxKly4sGJjYxUTE6NSpUrplVdeUbdu3W67hsVmsxm7tc09Uq1EPaNDAABI+vH8aaNDAAD8Rfr1RKNDuGPjynUydP3JJ5Ybur6zuGcPAAAAAEyINk4AAAAALs3o5+zlVlT2AAAAAMCESPYAAAAAwIRo4wQAAADg0mjidA6VPQAAAAAwISp7AAAAAFyaGZ+zlxOo7AEAAACACZHsAQAAAIAJ0cYJAAAAwKXxnD3nUNkDAAAAABOisgcAAADApVHXcw6VPQAAAAAwIZI9AAAAADAh2jgBAAAAuDSes+ccKnsAAAAAYEJU9gAAAAC4NBtbtDiFyh4AAAAAmBDJHgAAAACYEG2cAAAAAFwaG7Q4h8oeAAAAAJgQlT0AAAAALs3KBi1OobIHAAAAACZEsgcAAAAAJkQbJwAAAACXRhOnc6jsAQAAAIAJUdkDAAAA4NLYoMU5VPYAA1WsUkGzo6dp95HPtfOnTzX/wxl6ol4Nhzkenvm1/9ed+uHMVxl+Nn+1yqDIAcCc3N3dNWJ4Px3Yv0WXUo7p6OGv9N70N+XjUzjLcypX9lfqxaNatPC9HIwUAG6Pyh5gkGo1q2jx6jlys1j04ZJY/frL72r2fBMt/Gi2xg16Xf+z7nNJUoVK5eXu7q4PFn+k/d/+4HCNP//8J7kr8wAAIABJREFU04jQAcC0oqNm64X2LfXhirWaNWuhatZ8VAMH9FCd2jUV8lQbpaWlOczPkyePlkaGy9PT06CIASBrJHuAQca/PVpeXp7q2Wag9uzcK0laEblai2Jn69Upo7Rr69dKuZiqgCoVJEnrVm7WD/sOGRkyAJha27bP6YX2LTV12hyNe3mSffzUqV808a1xatXqGX300QaHc15/baSqVPbP6VCB+47V6AByKdo4AQOULFVcVR+rpB1f7rYnepJ048YNLZ23XD5FC6tpy6ck3Wz1tFqtOvbTcaPCBYD7Qp9enZWUdF5vvDndYXzR4uWaNHmm/jhz1mH8ycBaGjVyoF5/Y1pOhgkA/5jLJHvnzp3Tzp07lZCQkKFFAjCbkqVKSJJ+ij+a4djJn09Lkqo+VlmSVLFyBf36y++6cvmKJMnTi1YhALjb3NzcFBRUW3Hbdunq1auSJE9PD7m7u+vcuWRNeO0dbdv+lX1+wYIFtGTxTK1Z+7E++HCtUWEDQLZyPNl78cUXdfSo439wp02bppCQEPXu3Vtt2rRR48aN9cknn+R0aECOuZW4FSjoleGYT5GbmwAUL1lMkuRfubyuXr6qGYun6JvjW7Tn+BZ9+u0adXyxXc4FDAAm98gjZeXp6amTJ37RCy+01IH9W5R68ZhSLx7VyhXv64EHSjjMf2/6mypQwEsDB401KGLg/mIz+E9ulePJ3q5du5SSkmJ/vWzZMi1cuFBNmzbVtGnTFBYWprJly2rEiBHavn17TocH5Ihjh4/r4vmLCmlaX55eHg7Hmra42b6Z3yO/SjzgJ5+ihfWwf1kln0vWmAETNGHERCWdS9Yrk0dqxKuDjAgfAEynyP/ttvlMs6e08P3pio3dqLbte2lW+EK1eK6ptn65WoULe0uSWrb8j3r2CFX/AaOVnHzeyLABIFuGb9ASFRWl1q1ba/Lkyfaxdu3aqU+fPpo3b56Cg4MNjA64N9LTb2jBzKUa+fpQRcRM18yJc5V07ryaPf+0WrRvprTraUpPS1d6+g3NmBih40dO6ouP4+znr1uxWcs3L1SPgZ0UG7Nep46fNvDdAEDuly9fXklS5Ur+atmqmzZ//IUkad26/9HJk78ofNYkDR/WR3PnLdX8uVO1eMkH2rjpMyNDBu4rbNDiHMPv2UtMTNSzzz6bYbxDhw46dIidB2FekXOXK3zKfFV/vKqWbVqgj7/+SM+HPqsRvcbJzd1NFy+kKOlsshbOinJI9KSbG7l8GBkrd3d31QuuZdA7AADzuPx/7fXHjp2wJ3q3LFy0XOnp6Xq6cQMtmP+u0tPTNWnyTPn6FpGvbxEV+b/2+/z588nXt4g8PT0yXB8AjGBIZc9isdj/XrJkSYfXt6Snp8vDgw9LmNv895YoZuFK+Vcqr0uX/tSRhGN6sFwZubu769TxX7I9N+lssqTM7/sDANyZU6cTJUm///5HhmNpaWlKSjqvQt4FFRh48wu2o4e/yjAvtMPzCu3wvN4Me1dvhk3PcBwAcpohyd6MGTNUt25dVa1aVUFBQVq2bJmCgoLsxy9duqSFCxeqSpUqRoQH5IhnWj2tK5evKO6zndq354B9vE79JyRJe3btVYt2z6j/f3tp6uuztPUTx3tYH/EvJ0m3TQoBALeXlHReP/98UhUrlpebm5us1v9vGitYsID8/Hy159vv9d//vp7hXN9iRbR82Vx9+ulWvTt9nn4+fjIHIwfuD7l5kxQj5Xiy1759ex06dEhz5861P2LBYrEoLi5ODRs21Oeff67x48crNTVVy5Yty+nwgBzTqVd7lS3/oJrXbac/L12WJPn6FVXvIV2VcPAnfbPjO1V9rJLKPvKguvR5wSHZ8ylaWN36d9S5P5K0Y0vGb5cBAHcuetkqvTZhpAYO6KHZcxbbx0eNHCg3Nzet+miDvvgy4+ZxpUs/IEn67fc/Mj0OAEbJ8WQvLCxM0s02zSNHjuiHH37QoUOHVLZsWUnSlStX5O/vr6FDh6pGjRo5HR6QY+a/t0Rzl0/X4tg5WvPhRuXPn1+hPdvIp6iPRvZ9VZIUv/9HLV+0Sp16tdeS1RH6ZMMXKuzjrfbdWsunSGEN6T5a165eM/idAIA5TJ02V82bP63p776h6tWraM+e7xUUVEddOrfVp59uVUxMrNEhAvctNmhxjsVms5myJlqtRD2jQwBuq/5Tgeo3oqcqVHpE165e03dffa85Uxfo58Mn7HMsFos693lBbTu3VNmHH9SVK1f1/Z4DmjttkX74PsG44IF/6Mfz7BaL3KNAAS+NGztUHV5opVKlSigx8Xcti/lIk6eE2zuS/q506Qd08vi3Whq1Ur16j8jhiIE7l3490egQ7lj3cm0NXX/pidz5ZQ/JHgDgniLZAwDXQrJ353Jrsmf4c/YAAAAAIDtWc9an7jnDn7MHAAAAALj7qOwBAAAAcGnU9ZxDZQ8AAAAATMjwyp7NZtMnn3yir7/+WhcvXpSvr68aNGig4OBgo0MDAAAAgFzL0GQvNTVVL774og4ePCiLxaKCBQvaH6beoEEDzZ49W3nz5jUyRAAAAAAGs9LI6RRD2zinTp2qI0eOaNKkSdq/f7/27Nmj/fv3680339TXX3+tuXPnGhkeAAAAAORahiZ7X375pQYPHqw2bdooX758kqT8+fOrffv2GjBggNauXWtkeAAAAABcgM3gP7mVocnepUuX5O/vn+mxypUrKzk5OYcjAgAAAABzMDTZq1u3rtavX5/psbi4ONWuXTuHIwIAAAAAczB0g5YuXbpo5MiRGjhwoF544QWVLFlS58+f1+bNm7VmzRqNGzdOX3zxhX1+48aNDYwWAAAAgBGsRgeQS1lsNpthTaiVKlVyeG2xWCTdfBzD319bLBYlJCT842tXK1HvLkUJAPg3fjx/2ugQAAB/kX490egQ7liHss8buv6Kk7lzLxFDK3sLFiwwcnkAAAAAuQCPXnCOockeD04HAAAAgHvD0GRPks6dO6e5c+dq165dSk1NVZEiRVS3bl317dtXxYsXNzo8AAAAAMiVDN2N848//lDbtm31wQcfqGDBgqpevbry5cun5cuXq23btjp79qyR4QEAAABwATxnzzmGVvZmzJih69evKzY2VpUrV7aPJyQkqHfv3po1a5bCwsIMjBAAAAAAcidDK3vbtm3T4MGDHRI96eYD1QcOHKi4uDiDIgMAAACA3M3Qyt6lS5f00EMPZXrsoYce0vnz53M4IgAAAACuhufsOcfQyt5DDz2kPXv2ZHrsm2++0QMPPJDDEQEAAACAORia7LVp00aLFy/W0qVLlZKSIklKSUlRZGSklixZohYtWhgZHgAAAAAXYLPZDP3JrSw2A6NPT0/XgAEDtH37dlksFuXLl0/Xr1+XzWZTUFCQ5s2bp7x58zp17Wol6t3laAEAzvjx/GmjQwAA/EX69USjQ7hjrR8ytgi05tQGQ9d3lqH37OXJk0cLFizQli1btHv3bl24cEE+Pj4KDAxUo0aNjAwNAAAAAHK1HE/21q5dqwYNGqho0aL2sUaNGpHcAQAAAMiUNRc/685IOX7P3rhx43TixImcXhYAAAAA7is5XtnLzTc4AgAAAMh5PHrBOYbuxgkAAAAAuDcM2aAlJSVFSUlJ/2iur6/vPY4GAAAAAMzHkGRvwIAB/3huQkLCPYwEAAAAgKuzsUGLUwxJ9lq3bq1SpUoZsTQAAAAA3BcMSfbatWunxx9/3IilAQAAAOQyPHrBOWzQAgAAAAAmRLIHAAAAACaU422crVu3VrFixXJ6WQAAAAC5FM/qdk6OJ3uTJ0/O6SUBAAAA4L5jyAYtAAAAAPBPWY0OIJfinj0AAAAAMCGSPQAAAAAwIdo4AQAAALg0G8/ZcwqVPQAAAAAwIZI9AAAAADAh2jgBAAAAuDQrbZxOobIHAAAAACZEZQ8AAACAS7PZqOw5g8oeAAAAAJgQyR4AAAAAmBBtnAAAAABcGhu0OIfKHgAAAACYEJU9AAAAAC7NRmXPKVT2AAAAAMCESPYAAAAAwIRo4wQAAADg0qw8Z88pVPYAAAAAwISo7AEAAABwadT1nENlDwAAAABMiGQPAAAAAEyINk4AAAAALs1KI6dTqOwBAAAAgAlR2QMAAADg0qjsOYfKHgAAAACYEMkeAAAAAJgQbZwAAAAAXJrNRhunM6jsAQAAAIAJUdkDAAAA4NLYoMU5VPYAAAAAwIRI9gAAAADgHklPT1doaKgmTJiQ4VhcXJzat2+vGjVqKCgoSGFhYbp06ZLDHJvNpsWLF6tp06Z69NFH1bRpU0VGRv6j+xhJ9gAAAAC4NJvBf5x1+fJlDRs2TPv27ctwbNu2bRowYIBKlCih6dOnq1evXoqNjdXgwYMd5s2YMUNTp05V06ZNFR4eruDgYE2ePFlz58697frcswcAAAAAd1lcXJwmT56s8+fPZ3p86tSpqlKlisLDw2WxWCRJDzzwgIYPH65t27apQYMGOnPmjBYtWqQePXpo5MiRkqSQkBBZrVbNmzdPXbp0kbe3d5YxUNkDAAAAgLsoJSVF/fr1U0BAgNavX5/h+K+//qrDhw+rWbNm9kRPkp5++ml5eXnpiy++kCTt3r1baWlpat68ucP5LVq00LVr17Rjx45s46CyBwAAAMCl5bbn7Hl4eGjTpk0qX758psePHj0qSRmO582bV2XKlLEfz2reww8/LEk6cuRItnGQ7AEAAABANlJSUpSSkpJh3NvbO9M2ynz58mWZ6ElSamqqJKlgwYIZjhUoUMB+PCUlRe7u7vLy8nKYc+u8W/OyQrIHAAAAwKUZ/Zy9pUuXavbs2RnGBw8erCFDhtzx9axWqyQ5tHD+lZvbzbvtbDZbpnNujd2alxWSPQAAAADIRvfu3dW6desM49ltjpKdW+f9/TELkvTnn3/Kx8fHPi89PV1XrlyRp6enfc6til6hQoWyXYdkDwAAAACykVW7prNutXgeP35cDRs2tI+npaXp9OnTqlWrlsO8EydOqHLlyvZ5x48flyRVqFAh23XYjRMAAACAS7PZbIb+3G1lypRRhQoV9PHHH9tbOiXp888/15UrV+wJYHBwsNzd3bVx40aH8zds2CAPDw/VrVs323Wo7AEAAABADhsxYoQGDRqkgQMHqn379jp16pRmzpypwMBAhYSESJL8/PzUpUsXLVq0SDdu3FC9evW0fft2LV++XEOHDlXRokWzXYNkDwAAAIBLM3qDlnvh6aef1qxZsxQREaHhw4fLx8dHbdu21YgRIxzmjRkzRoULF1ZsbKxiYmJUqlQpvfLKK+rWrdtt17DYcttDK/6haiXqGR0CAEDSj+dPGx0CAOAv0q8nGh3CHXus5JOGrr//912Gru8s7tkDAAAAABOijRMAAACAS7OZsI0zJ1DZAwAAAAATorIHAAAAwKVZzbnNyD1HZQ8AAAAATIhkDwAAAABMiDZOAAAAAC6NDVqcQ2UPAAAAAEyIyh4AAAAAl8YGLc6hsgcAAAAAJkSyBwAAAAAmRBsnAAAAAJfGBi3OobIHAAAAACZEZQ8AAACAS2ODFudQ2QMAAAAAEyLZAwAAAAAToo0TAAAAgEtjgxbnUNkDAAAAABMi2QMAAAAAE6KNEwAAAIBLYzdO51DZAwAAAAATorIHAAAAwKWxQYtzqOwBAAAAgAmR7AEAAACACdHGCQAAAMCl2WxWo0PIlajsAQAAAIAJUdkDAAAA4NKsbNDiFCp7AAAAAGBCJHsAAAAAYEK0cQIAAABwaTYbbZzOoLIHAAAAACZEZQ8AAACAS2ODFudQ2QMAAAAAEyLZAwAAAAAToo0TAAAAgEtjgxbnUNkDAAAAABOisgcAAADApVmp7DmFyh4AAAAAmBDJHgAAAACYEG2cAAAAAFyajefsOYXKHgAAAACYEJU9AAAAAC6NRy84h8oeAAAAAJgQyR4AAAAAmBBtnAAAAABcmpUNWpxCZQ8AAAAATIhkDwAAAABMiDZOAAAAAC6N3TidQ2UPAAAAAEyIyh4AAAAAl2alsucUKnsAAAAAYEIkewAAAABgQrRxAgAAAHBpbNDiHCp7AAAAAGBCVPYAAAAAuDSrqOw5g8oeAAAAAJgQyR4AAAAAmBBtnAAAAABcGhu0OIfKHgAAAACYEJU9AAAAAC7NSmXPKVT2AAAAAMCESPYAAAAAwIRo4wQAAADg0mw8Z88pVPYAAAAAwISo7AEAAABwaWzQ4hwqewAAAABgQiR7AAAAAGBCtHECAAAAcGk22jidQmUPAAAAAEyIZA8AAAAATIg2TgAAAAAujefsOYfKHgAAAACYEJU9AAAAAC6NDVqcQ2UPAAAAAEyIZA8AAAAATIg2TgAAAAAujTZO51DZAwAAAAATorIHAAAAwKVR13MOlT0AAAAAMCGLjQZYAAAAADAdKnsAAAAAYEIkewAAAABgQiR7AAAAAGBCJHsAAAAAYEIkewAAAABgQiR7AAAAAGBCJHsAAAAAYEIkewAAAABgQiR7QA6x2WxGhwAAAID7SB6jAwBcxdixY7VmzRqNHz9eXbp0yXB806ZNeumllxQVFaW6deve0bXff/99Xbx4UaNGjcr0+Ndff61u3brd9jp16tRRdHT0Ha3trL1796pjx46ZHouLi1PJkiVzJA4AuFO3Ps9vZ/LkyWrTpk0ORCSNHz9eK1euzDAeGBioyMjIHIkBwP2HZA/4m6lTpyowMFDly5e/a9d899131aFDhyyPV6lSRTExMfbX586d07BhwxQaGqoWLVrYxwsVKnTXYrqdQ4cOSZIWLVokDw8Ph2NFixbNsTgA4E71799f7dq1s7+OjY3V6tWrFRERocKFC9vHH3744RyLKT4+XnXq1NGwYcMcxr29vXMsBgD3H5I94C/c3d3l7u6uUaNGacWKFcqbN2+OrFuoUCHVqlXL/vqXX36RJJUuXdphPCfFx8erdOnSql+/viHrA4CzypUrp3Llytlf7969W5JUvXp1+fn55Xg8aWlpOnz4sPr372/YZzqA+xP37AF/4e7urldeeUXx8fGaPXv2beenp6crJiZGrVq1Uo0aNRQYGKjRo0frt99+k3QzaQsICJAkrVixQgEBAfZE7t/67rvv1KtXL9WrV081atRQ586dtW3bNoc5QUFBmjJlimbPnq369eurZs2a6tq1q7777rvbXj8+Pl7VqlW7K7ECgCtLS0tTZGSkWrRooccee0xBQUEaN26czpw5Y5+zbds2BQQEaNu2berXr5993oQJE5SSkpLt9Y8cOaK0tDRVrVr1Xr8VAHBAsgf8Tdu2bdWkSRMtWLBAe/fuzXbu8OHDNXHiRAUGBmrmzJkaPHiwdu7cqXbt2um3335T8eLF7e2ZjRs3VkxMjIoXL/6vY9y0aZM6d+6stLQ0vfbaa5oyZYry5Mmjvn37ZrhPZc2aNVq7dq1GjhypSZMmKSUlRd27d9eBAweyvP61a9d07NgxpaamKjQ0VNWrV1ft2rU1evRonTt37l/HDwCuwmazaeDAgZo6daoaNGigWbNmqX///tqyZYvat2+vP/74w2H+qFGj5OXlpRkzZqh79+5at26devbsqRs3bmS5Rnx8vCTpyy+/1FNPPaUqVaqoSZMmio6OZvMuAPcUbZxAJt588019//33Gj16tNatW6cCBQpkmLNr1y599tlnGjFihPr3728fr1Onjp5//nmFh4dr0qRJ9padYsWK3ZX2nRs3bmjixIkKCAhQZGSk3NxufmfTtGlTtWvXTlOmTNGzzz6rfPnySZKuXr2qtWvX6oEHHpB0czOAJk2aKDw8XAsWLMh0jZ9++knp6ek6evSoXnrpJZUpU0Y//PCDIiIi9P3332v16tUqWLDgv34vAGC0rVu3atu2bRo7dqx69uxpH3/iiSfUtm1bzZ07V6+99pp9vGbNmnrvvfckSY0aNZKvr69efvllffLJJ2revHmma9xK9s6ePas33nhDNptNmzZt0ltvvaXffvtNo0ePvofvEMD9jMoekImiRYtq4sSJOn36tCZOnJjpnF27dkmSWrdu7TDu7++vGjVq2O8RudsOHz6spKQkPf/88/ZET5Lc3NzUtm1bXbhwwf4fC0lq0KCBPdGTJB8fHwUHB+ubb77Jco1y5cppwYIFWrVqlVq3bq3atWurZ8+eevfdd3Xy5El98MEH9+S9AUBOy+qzvEqVKqpatar9+C0vvPCCw+vnnntOFotFX3/9dZZrdOvWTfPnz1dERISCg4PVoEEDvf3222revLkiIyMzVA8B4G4h2QOy0LBhQ4WGhio2Nlaff/55huMXLlyQxWLJ9GZ/Pz+/297D4awLFy5IUqbtoLfG/rp2Zo9I8PX11dWrV3X16tVM1/D29laDBg0ynFu/fn15eHgoISHB6fgBwJVcuHBB+fLlk4+PT4Zjfn5+Sk1NdRj765dnkpQ/f34VLFhQFy9ezHKNRx55RCEhIQ5f0Ek32/tv3Lihn3766V+8AwDIGskekI2xY8eqXLlyGj9+fIZ71Xx8fGSz2XT27NkM5505c0ZFihS5JzHd+g9JZt8E39pM4K9rJycnZ5h39uxZFShQIMMjFW45ePCgoqOjdeXKFYfx9PR0paen8+gFAKbh4+Oj69ev279I+6vMPsv//pl69epVpaamqlixYlmusX79en322WcZxm99xvKZCuBeIdkDsuHp6ampU6cqJSUlw+6cgYGBkpRhQ5SjR49q//79Dg9e//u3uf+Gv7+/fH19tW7dOlmtVvu41WrV6tWrVbhwYVWqVMk+vmPHDodvps+fP68dO3YoODg4yzWOHj2qt956S5988onD+IYNG5Senm5/7wCQ22X1WZ6QkKCEhASHz3JJ2rx5s8PrDRs2SFK2n6mrVq3Sq6++6tB1YbPZtH79evn5+cnf3/9fvQcAyAobtAC3Ub16dfXv3z9DshcUFKRGjRpp1qxZunjxourVq6fExERFRETI29tbAwcOtM/19vbWwYMHtXv3btWoUUOenp5Ox5MnTx6NGTNGY8aMUY8ePdSpUydZLBZ98MEHio+P11tvvWXfnEWSfffNPn36yGq1at68ebJarRo+fHiWazRr1kxLly5VWFiYkpKSVLFiRe3du1cLFy5USEiIGjdu7HT8AOBKGjVqpPr162vatGlKSkpSnTp1dPr0ac2ZM0dFixZVv379HOavWbNG+fPnV8OGDfXjjz863IeXlWHDhql79+7q2bOnevfurTx58mjlypXas2ePpk+f7vCZDQB3E8ke8A8MGDBA27Zty/C4glmzZun999/X+vXrFR0dbd/8ZOjQoQ73dQwaNEhz5sxR//79tXjxYj3xxBP/Kp5WrVrJx8dH8+fP19ixY+Xm5qaqVavq/fffV8OGDR3mNmzYUFWrVtUbb7yhtLQ01alTRzNmzNDDDz+c5fU9PDy0ZMkSzZkzR8uXL9eZM2dUokQJ9e7d22HnUQDI7SwWi+bOnau5c+dqw4YNioyMlI+Pj0JCQjRs2DCVKFHCYf7LL7+sLVu2aMiQIfL19VWPHj00aNAgWSyWLNeoVauWoqOjNXv2bL3++uu6du2aKleurPnz52f4zAaAu8li4wEvgGkFBQXpscceU0REhNGhAECutm3bNvXp00dz5szR008/bXQ4APCPcM8eAAAAAJgQyR4AAAAAmBBtnAAAAABgQlT2AAAAAMCESPYAAAAAwIRI9gAAAADAhEj2AMAkwsPDFRAQkOGnWrVqql+/voYNG6ZDhw7lSCzr1q1TQECAVq9ebR8LCAhQjx49nLrezz//fJci+389evRQQEDAXb8uAACugoeqA4DJdOjQQU888YT9dXp6uk6dOqXo6Ght3bpVMTExqlatWo7H9c4776h48eJ3fN68efMUERGhAwcO3IOoAAAwL5I9ADCZGjVqqFWrVhnGH330UQ0aNEjh4eGaP39+jseVWUz/xM6dO5Wenn6XowEAwPxo4wSA+0Tjxo1VoEABffvtt0aHAgAAcgCVPQC4T1gsFrm5udmrZE899ZQqVaqkihUrKioqSm5ubnr99df13HPP6caNG4qKitLq1at14sQJeXp6qnbt2hoyZIgqVarkcN2DBw9q5syZ2rdvn/LkyaNmzZqpYsWKGdYPCAhQYGCgIiMj7WPHjh1TRESEvvrqK/3555968MEH1aFDB3Xu3FkWi8XhnrqAgAC1bt1aU6ZMkST9+uuvCg8P1/bt23XhwgWVLFlSzZo104ABA+Tl5eWwdkxMjJYvX67Tp0+rdOnS6tev3936tQIA4LJI9gDgPrF//36lpqaqTp069rHdu3fr0KFDeumll/T777+rdu3astlsGjZsmD7//HM9++yz6tixo5KSkrRixQp16NBBixYtUq1atezX7Natm7y8vPTiiy/K09NTH330kdavX3/beA4dOqTOnTvLzc1NnTp1UunSpbV161aFhYUpMTFRY8aM0TvvvKN58+bpxIkTmjJlih566CFJ0okTJxQaGirp5j2KJUuW1IEDB7Rw4ULt3r1by5Ytk4eHhyRp8uTJioyMVJ06ddSxY0clJiZq/PjxypOHfwIBAObGv3QAYDKXL19WcnKy/fXVq1f1ww8/6J133pHFYlH//v0d5kZERCgwMNA+tnHjRn322Wd69dVX1bVrV/t4586d1bJlS02YMEGbN2+WJE2ZMkVubm5auXKlHnzwQUk3k6/27dvr2LFj2cY5adIkXbt2TWvWrLFX8Dp06KDevXsrOjpaffv2VatWrfTRRx/p5MmTDvf8hYWFyWq1au3atSpVqpQkqWPHjqpXr55Gjx6tqKgo9e3bV8ePH1dUVJQaNWqkiIgIubndvHuhQYMGTu8MCgBAbsE9ewBgMmFhYQoMDLT/NGrUSEOGDJHVatX06dMVFBRkn+vl5aW6des6nL9582a5ubmpSZMmSk5Otv9IUnBwsI4dO6Zjx44pOTl39S2iAAAEOElEQVRZ+/btU0hIiD3Rk6QCBQqoU6dO2caYnJysb7/9ViEhIQ6tmhaLRRMnTtS6detUqFChTM+9cOGCdu7cqbp168rDw8Mhxvr168vLy0ufffaZJGnLli2yWq3q1KmTPdGTpMDAQFWtWvUf/kYBAMidqOwBgMn06tVL9evXl3QzecqbN69KliypMmXKZJhbpEgRhyRIutkiabVa1bBhwyzXSExM1J9//imbzaayZctmOF6hQoVsY0xMTJTNZlO5cuUyHCtZsmS25546dUo2m02ffvqpPv3000zn/Prrr5Kk06dPS1Km6/j7+ys+Pj7btQAAyM1I9gDAZCpUqKAnn3zyH811d3fPMGa1WuXt7a2ZM2dmeV6lSpWUmJgoSbp27Vqm18jOjRs3JEn58+f/R3Fmdu3mzZurffv2mc65dT+exWLJMsZbMQAAYFYkewAAB2XKlNGJEydUrVo1eXt7Oxzbu3evLl26JA8PDz344INyc3PT8ePHM1zj5MmT2a5RunRpSTeriH/3zTffaOXKlerdu3eGnT9vxSdJ169fz5DU2mw2ffzxx/Y5t6qOP//8s/z9/R3mnjp1KtsYAQDI7bhnDwDg4D//+Y9sNptmzZrlMJ6UlKTBgwdr1KhRslgs8vHx0ZNPPqm4uDgdOnTIPu/69euKiYnJdg0/Pz899thj2rp1q73V8pbFixdr8+bN8vPzkyS5ubk5VAqLFSumxx9/XFu2bNGBAwcczl2zZo1GjBih2NhYSVKTJk2UN29eLVy4UGlpafZ53333nfbv338HvxUAAHIfKnsAAAetW7fW5s2bFR0drRMnTigkJESXL1/Whx9+qOTkZL399tvy9PSUJL388ssKDQ1V165d1a1bN/n4+Gjt2rVKSkq67TqvvvqqunXrpnbt2qlz587y8/PTli1bFBcXp5deekm+vr6SbiZ3NptN4eHhqlWrlgIDA/Xaa6+pc+fO6tq1q0JDQ1W+fHklJCRo1apVKl26tAYOHChJKlWqlIYOHap3331XHTt2VMuWLZWUlKSoqCgVLVrUYddSAADMhmQPAOAgT548mj9/vpYsWaINGzbo7bffVoECBVSpUiWFhYU57OZZvnx5rVixQu+9955iYmJ048YNNWrUSAMGDNCQIUOyXad69epauXKlwsPDtWzZMl2/fl2PPPKIpk6dqpYtW9rn9enTR4cPH9b8+fO1b98+BQYGqlKlSoqNjdWcOXO0ceNGXbx4UcWLF1e7du00YMAAlShRwn5+3759VbJkSS1evFjTpk1TsWLFNHLkSB08eFBr1qy5+79AAABchMVms9mMDgIAAAAAcHdxzx4AAAAAmBDJHgAAAACYEMkeAAAAAJgQyR4AAAAAmBDJHgAAAACYEMkeAAAAAJgQyR4AAAAAmBDJHgAAAACYEMkeAAAAAJgQyR4AAAAAmND/Ah5yvGSAh6scAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set(font_scale=1.6)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(16,12))\n",
    "sns.heatmap(cm, annot=True, ax = ax, fmt=\"d\")\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True') \n",
    "ax.set_title('Confusion Matrix')\n",
    "ax.xaxis.set_ticklabels([\"Not Top 5\", \"Top 5\"])\n",
    "ax.yaxis.set_ticklabels([\"Not Top 5\", \"Top 5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion/Further Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chosen random forest model had trouble identifying Top 5 tracks. It is very possible that the features I chose are not adequate to make accurate predictions, as Top 5 tracks are very diverse. \n",
    "\n",
    "As a first additional step, I would conduct error analysis by randomly choosing some misclassified tracks. If a pattern was evident as to why tracks were consistently misclassified, I could adjust the model/add more complicated features to improve it. Second, I would include additional features extracted from the actual lyrics of the tracks. Perhaps the presence of certain words, bigrams, or trigrams would aid in prediction. I also suspect that non-musical features, such as marketing budget, general popularity of the artist, etc. have a significant influence of which tracks break into the top spots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
